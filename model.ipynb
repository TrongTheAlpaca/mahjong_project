{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json  # for checkpointing\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.colors\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "load_dotenv(find_dotenv('config.env'))\n",
    "\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=0, suppress=True, linewidth=160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreword about PyTorch Version\n",
    "This notebook is designed to be used with **PyTorch 1.7.1**. \n",
    "\n",
    "However, future versions \n",
    "In PyTorch version **1.9.0 and newer** (which is at the time of writing still **unstable**), new parameters such as `batch_first` in `torch.nn.MultiheadAttention` are available, which can make it easier to configure the model creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loaded PyTorch Version: {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed Library: `svgutils 0.3.1`\n",
    "**NOTE:** Install svgutils version 0.3.1, newer version will crash our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y svgutils=0.3.1 -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -y -c conda-forge python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT PAGES\n",
    "### https://seaborn.pydata.org/examples/index.html\n",
    "### https://seaborn.pydata.org/generated/seaborn.diverging_palette.html\n",
    "### https://medium.com/@morganjonesartist/color-guide-to-seaborn-palettes-da849406d44f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diverging_palette_dark = sns.diverging_palette(250, 15, s=75, l=40, n=2, center=\"dark\")\n",
    "diverging_palette_light = sns.diverging_palette(240, 10, n=2, center=\"light\")\n",
    "diverging_palette_heatmap = sns.color_palette(\"icefire\", as_cmap=True)\n",
    "\n",
    "display(diverging_palette_dark)\n",
    "display(diverging_palette_light)\n",
    "display(diverging_palette_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT PAGES\n",
    "# \n",
    "\n",
    "# for p in sns.palettes.SEABORN_PALETTES:\n",
    "#     print(p)\n",
    "#     sns.set_palette(p)\n",
    "#     sns.palplot(sns.color_palette())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style(\"ticks\")\n",
    "# sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "sns.set_style(\"whitegrid\")\n",
    "# sns.set_style(\"darkgrid\")\n",
    "\n",
    "sns.set_palette('bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_status_print():\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print(\"Total:     {:>4.1f} GB\".format(round(torch.cuda.get_device_properties(0).total_memory / 1024 ** 3, 1)))\n",
    "    print('Allocated: {:>4.1f} GB'.format(round(torch.cuda.memory_allocated(0) / 1024 ** 3, 1)))\n",
    "    print('Cached:    {:>4.1f} GB'.format(round(torch.cuda.memory_reserved(0) / 1024 ** 3, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ticks_tiles_newlined = [\n",
    "    \"1\\nman\",\n",
    "    \"2\\nman\",\n",
    "    \"3\\nman\",\n",
    "    \"4\\nman\",\n",
    "    \"5\\nman\",\n",
    "    \"6\\nman\",\n",
    "    \"7\\nman\",\n",
    "    \"8\\nman\",\n",
    "    \"9\\nman\",\n",
    "    \"1\\npin\",\n",
    "    \"2\\npin\",\n",
    "    \"3\\npin\",\n",
    "    \"4\\npin\",\n",
    "    \"5\\npin\",\n",
    "    \"6\\npin\",\n",
    "    \"7\\npin\",\n",
    "    \"8\\npin\",\n",
    "    \"9\\npin\",\n",
    "    \"1\\nsou\",\n",
    "    \"2\\nsou\",\n",
    "    \"3\\nsou\",\n",
    "    \"4\\nsou\",\n",
    "    \"5\\nsou\",\n",
    "    \"6\\nsou\",\n",
    "    \"7\\nsou\",\n",
    "    \"8\\nsou\",\n",
    "    \"9\\nsou\",\n",
    "    \"\\nEast\",\n",
    "    \"\\nSouth\",\n",
    "    \"\\nWest\",\n",
    "    \"\\nNorth\",\n",
    "    \"\\nHaku\",\n",
    "    \"\\nHatsu\",\n",
    "    \"\\nChun\"\n",
    "]\n",
    "\n",
    "ticks_tiles_oneline = [\n",
    "    \"1 man\",\n",
    "    \"2 man\",\n",
    "    \"3 man\",\n",
    "    \"4 man\",\n",
    "    \"5 man\",\n",
    "    \"6 man\",\n",
    "    \"7 man\",\n",
    "    \"8 man\",\n",
    "    \"9 man\",\n",
    "    \"1 pin\",\n",
    "    \"2 pin\",\n",
    "    \"3 pin\",\n",
    "    \"4 pin\",\n",
    "    \"5 pin\",\n",
    "    \"6 pin\",\n",
    "    \"7 pin\",\n",
    "    \"8 pin\",\n",
    "    \"9 pin\",\n",
    "    \"1 sou\",\n",
    "    \"2 sou\",\n",
    "    \"3 sou\",\n",
    "    \"4 sou\",\n",
    "    \"5 sou\",\n",
    "    \"6 sou\",\n",
    "    \"7 sou\",\n",
    "    \"8 sou\",\n",
    "    \"9 sou\",\n",
    "    \"East\",\n",
    "    \"South\",\n",
    "    \"West\",\n",
    "    \"North\",\n",
    "    \"Haku\",\n",
    "    \"Hatsu\",\n",
    "    \"Chun\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# PARAMETERS\n",
    "##############################################\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "EPOCHS = 30\n",
    "DATASET_CONFIG = 'final_small'\n",
    "SHUFFLE_DATASET = True\n",
    "\n",
    "LOAD_TEST_DATASET_ONLY = False\n",
    "\n",
    "cuda_status_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class DiscardDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    class DiscardType(Enum):\n",
    "        DISCARD = 0\n",
    "        POOL    = 1\n",
    "\n",
    "    def __init__(self, data_path, years: list, n_rows: int = None, phase: int = None, balance_data: bool = False, discard_type=DiscardType.DISCARD, singular=False):\n",
    "        \"\"\" \n",
    "        If n_rows = None -> get all \n",
    "        param: singular: If True, pick 1 state per game at random!\n",
    "        \"\"\" \n",
    "        \n",
    "        # Invalid Parameter Combinations\n",
    "        if balance_data:\n",
    "            if not n_rows:\n",
    "                raise BaseException(\"`n_rows` must be defined if `balance_data` is True!\")\n",
    "            elif n_rows < 34:\n",
    "                raise BaseException(\"Cannot balance data if `n_rows` < 34!\")\n",
    "        \n",
    "        ALL_YEARS = (2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019)\n",
    "        invalid_years = set(years) - set(ALL_YEARS)\n",
    "        if invalid_years:\n",
    "            raise Exception(f\"INVALID YEARS: {invalid_years}\")\n",
    "        \n",
    "        # Dataset Print\n",
    "        if n_rows:\n",
    "            print(f\"Loading Dataset with {n_rows:>13,} rows\", end=' ')\n",
    "        else:\n",
    "            print(f\"Loading Dataset with all rows\", end=' ')\n",
    "\n",
    "        if phase in [0, 1, 2]:\n",
    "            print(f\"(Phase {phase})\", end=' ')\n",
    "        else:\n",
    "            print(f\"(All Phases)\", end=' ')\n",
    "            \n",
    "        print(\"{:<14}\".format(\"<BALANCED>\" if balance_data else '<NOT BALANCED>'), end=' ')\n",
    "        \n",
    "        print(years)\n",
    "        \n",
    "        # Check if given discard_type is valid\n",
    "        if discard_type not in [DiscardDataset.DiscardType.DISCARD, DiscardDataset.DiscardType.POOL]:\n",
    "            raise BaseException(f\"INVALID discard type = {discard_type}! Use either `DiscardDataset.DISCARD` or `DiscardDataset.POOL`!\")\n",
    "        self.discard_type = discard_type\n",
    "\n",
    "        game_id_list = []\n",
    "        temp_matrices = []\n",
    "        finished = False\n",
    "        \n",
    "        # Used when balance_data = False and n_rows != None\n",
    "        loaded_rows = 0  \n",
    "        \n",
    "        # Used when balance_data = True\n",
    "        class_bins = np.zeros(34)\n",
    "        baseline_bin_size = n_rows // 34 if balance_data else -1  # The expected size of the smallest bin\n",
    "\n",
    "        if balance_data:\n",
    "            paths_load_bar = tqdm(total=baseline_bin_size * 34, unit='rows', position=0)\n",
    "        else:\n",
    "            paths_load_bar = tqdm(total=n_rows, unit='rows', position=0)\n",
    "\n",
    "        for year in years:\n",
    "\n",
    "            paths = (Path(data_path) / str(year)).iterdir()\n",
    "\n",
    "            for idx, path in enumerate(paths):\n",
    "                \n",
    "                if path.suffix != '.npz':\n",
    "                    continue\n",
    "                \n",
    "                game_id_list.append(path.stem)\n",
    "\n",
    "                arr = scipy.sparse.load_npz(path).toarray()  # Loads a single complete game\n",
    "\n",
    "                if phase in [0, 1, 2]:\n",
    "                    phased_matrices = self.generate_phase_column(arr)\n",
    "                    arr = phased_matrices[phase]\n",
    "                    \n",
    "                if singular:\n",
    "                    if arr.shape[0] <= 0:  # No rows found (This can happen if a game lack states from a certain phase)\n",
    "                        continue\n",
    "                    random_row_index = np.random.choice(arr.shape[0], 1, replace=False)\n",
    "                    arr = arr[random_row_index]  # Select 1 row per loaded game\n",
    "\n",
    "                temp_matrices.append(arr)\n",
    "\n",
    "                paths_load_bar.set_postfix(year=year, files_loaded=(idx + 1))  # Update Bar\n",
    "\n",
    "                if balance_data:\n",
    "                    \n",
    "                    class_bins += np.bincount(arr[:, -1], minlength=34)\n",
    "                    smallest_class_bin = int(np.amin(class_bins))\n",
    "\n",
    "                    paths_load_bar.n = smallest_class_bin * 34\n",
    "                    paths_load_bar.refresh()\n",
    "                    \n",
    "                    if baseline_bin_size <= smallest_class_bin:\n",
    "                        finished = True\n",
    "                        break\n",
    "\n",
    "                else:\n",
    "                    paths_load_bar.update(arr.shape[0])\n",
    "                    \n",
    "                    if n_rows:\n",
    "                        loaded_rows += arr.shape[0]\n",
    "                        if n_rows <= loaded_rows:\n",
    "                            finished = True\n",
    "                            break\n",
    "\n",
    "            if finished:  # Early Stopping\n",
    "                break\n",
    "\n",
    "        if not finished and n_rows is not None:\n",
    "            raise BaseException(\"`n_rows` is higher than found rows -- Either lower `n_rows` or include more annual datasets!\")\n",
    "\n",
    "        new_game_id_list = []\n",
    "        for i, t_matrix in enumerate(temp_matrices):\n",
    "            new_game_id_list.extend([game_id_list[i]] * t_matrix.shape[0])\n",
    "        new_game_id_list = np.array(new_game_id_list)\n",
    "        \n",
    "        if balance_data:\n",
    "            \n",
    "            matrix = np.concatenate(temp_matrices, axis=0)\n",
    "            sorted_indices = np.argsort(matrix[:, -1])\n",
    "            \n",
    "            matrix = matrix[sorted_indices]  # Sort rows by last column (the y-value)\n",
    "            new_game_id_list = new_game_id_list[sorted_indices]\n",
    "            \n",
    "            split_indices = np.where(np.diff(matrix[:, -1])!=0)[0]+1  # I was drunk\n",
    "            sorted_rows = np.array_split(matrix, split_indices)  # Organize rows according to their last column's value into a list\n",
    "            sorted_game_ids = np.array_split(new_game_id_list, split_indices)\n",
    "            \n",
    "            for i in range(len(sorted_rows)):\n",
    "                sorted_rows[i] = sorted_rows[i][:baseline_bin_size]  # The balancing action\n",
    "                sorted_game_ids[i] = sorted_game_ids[i][:baseline_bin_size]\n",
    "\n",
    "            final_arr = np.concatenate(sorted_rows, axis=0)\n",
    "            final_game_id_list = np.concatenate(sorted_game_ids, axis=0)\n",
    "\n",
    "        else:\n",
    "            final_arr = np.vstack(temp_matrices)\n",
    "            final_game_id_list = new_game_id_list\n",
    "            \n",
    "            if n_rows:\n",
    "                final_arr = final_arr[:n_rows]\n",
    "                final_game_id_list = final_game_id_list[:n_rows]\n",
    "                \n",
    "        # Extract Round Number and Steps from data\n",
    "        self.round_numbers = final_arr[:, 32].reshape(-1).tolist()\n",
    "        self.step_numbers  = (final_arr[:, 33] + 128 - 1).reshape(-1).tolist()        \n",
    "        final_arr[:, 32] = -128  # Reset to padding value\n",
    "        final_arr[:, 33] = -128  # Reset to padding value\n",
    "\n",
    "        # Finalize tqdm bar\n",
    "        paths_load_bar.n = final_arr.shape[0]\n",
    "        paths_load_bar.last_print_n = final_arr.shape[0]\n",
    "        paths_load_bar.refresh()\n",
    "        paths_load_bar.close()\n",
    "        \n",
    "        self.game_ids = list(final_game_id_list)\n",
    "        self.combined_x_data = torch.FloatTensor(final_arr[:, :-1])  # Must be Float it seems\n",
    "        \n",
    "        self.x_data = None\n",
    "        if self.discard_type == DiscardDataset.DiscardType.POOL:\n",
    "            self.use_pools()\n",
    "        else:\n",
    "            self.use_discards()\n",
    "        \n",
    "        self.y_data = torch.LongTensor(final_arr[:, -1])  # Must be Long it seems\n",
    "        \n",
    "    def use_pools(self):\n",
    "        self.discard_type = DiscardDataset.DiscardType.POOL\n",
    "        self.x_data = self.combined_x_data[:, 0:374]\n",
    "\n",
    "    def use_discards(self):\n",
    "        self.discard_type = DiscardDataset.DiscardType.DISCARD\n",
    "        self.x_data = torch.hstack((self.combined_x_data[:, :238], self.combined_x_data[:, 374:]))  # Slice away POOL data\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_phase_column(array: np.array) -> np.array:\n",
    "        # Begin with merging all pools together\n",
    "\n",
    "        merged_discards = array[:, 238:374]  # Pool\n",
    "        merged_discards = np.sum(merged_discards, axis=1)\n",
    "\n",
    "        phases = np.zeros([array.shape[0]])  # Early Game\n",
    "        phases[(24 < merged_discards) & (merged_discards <= 48)] = 1  # Mid Game\n",
    "        phases[(48 < merged_discards)] = 2  # End Game\n",
    "\n",
    "        return array[(phases == 0)], array[(phases == 1)], array[(phases == 2)]        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "#         X = self.x_data[idx, 0:374] if self.discard_type == DiscardDataset.DiscardType.POOL else torch.hstack((self.x_data[idx, :238], self.x_data[idx, 374:]))\n",
    "        return {\n",
    "            'game_id': self.game_ids[idx],\n",
    "            'round': self.round_numbers[idx],\n",
    "            'step': self.step_numbers[idx],\n",
    "            'X': self.x_data[idx],\n",
    "            'y': self.y_data[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from configurations\n",
    "ds_configs = pd.read_csv('Dataset Configurations.csv', index_col='dataset_name')\n",
    "selected_config = ds_configs.loc[DATASET_CONFIG]\n",
    "selected_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years(code: str) -> list:\n",
    "    code = int(f\"0b{code:0>11}\", 2)\n",
    "    found_years = []\n",
    "    for i in range(11):\n",
    "        if (code >> i) & 1:\n",
    "            found_years.append(2019 - i)\n",
    "    found_years.reverse()\n",
    "    return found_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balanced_data_options(code: str):\n",
    "    results = [False, False, False]\n",
    "    code = int(f\"0b{code:0>11}\", 2)\n",
    "    results[0] = code & 0b100 != 0\n",
    "    results[1] = code & 0b010 != 0\n",
    "    results[2] = code & 0b001 != 0\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLOADING DATASETS:\\n\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Setup of Parameters\n",
    "DATASET_PATH = Path(os.environ.get('DISCARD_DATASET'))  # Get path  # TODO: FIX TO NEW PATH\n",
    "BATCH_SIZE = int(selected_config['batch'])  # We must cast it or else it will crash\n",
    "BALANCED_TRAINING, BALANCED_VALIDATION, BALANCED_TEST = get_balanced_data_options(selected_config['balanced_data'])  # 3 boolean values\n",
    "PHASES = selected_config['phases']\n",
    "DISCARD_TYPE = DiscardDataset.DiscardType.POOL\n",
    "TEST_SINGULAR = True\n",
    "\n",
    "# Training Dataset\n",
    "train_dataset = None\n",
    "train_loader = None\n",
    "if not LOAD_TEST_DATASET_ONLY:\n",
    "    train_dataset = DiscardDataset(DATASET_PATH,\n",
    "                                   n_rows=selected_config['train_size'],\n",
    "                                   years=get_years(selected_config['years_training']),\n",
    "                                   phase=PHASES,\n",
    "                                   balance_data=BALANCED_TRAINING,\n",
    "                                   discard_type=DISCARD_TYPE\n",
    "                                  )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE_DATASET)\n",
    "\n",
    "# Validation Dataset\n",
    "validation_dataset = None\n",
    "validation_loader = None\n",
    "if not LOAD_TEST_DATASET_ONLY:\n",
    "    validation_dataset = DiscardDataset(DATASET_PATH,\n",
    "                                        n_rows=selected_config['validation_size'],\n",
    "                                        years=get_years(selected_config['years_validation']),\n",
    "                                        phase=PHASES,\n",
    "                                        balance_data=BALANCED_VALIDATION,\n",
    "                                        discard_type=DISCARD_TYPE,\n",
    "                                        singular=True\n",
    "                                       )\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE_DATASET)\n",
    "\n",
    "# Test Dataset\n",
    "test_dataset = DiscardDataset(DATASET_PATH, \n",
    "                              n_rows=selected_config['test_size'], \n",
    "                              years=get_years(selected_config['years_testing']),\n",
    "                              phase=PHASES,\n",
    "                              balance_data=BALANCED_TEST,\n",
    "                              discard_type=DISCARD_TYPE,\n",
    "                              singular=True\n",
    "                             )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=SHUFFLE_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_status_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset.x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset.game_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalid Data Checker\n",
    "On rare occasions, some training cases X may be invalid constructed (e.g. the whole tensor is added 1).\n",
    "\n",
    "How these corruptions occur is a mystery. If corrupted indices are found, redo the dataset loading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_corrupted_cases(dataset):\n",
    "    \"\"\" Return indices of corrupted X datas. \"\"\"\n",
    "    if dataset is not None:\n",
    "        return torch.nonzero(torch.sum(dataset.x_data[:, 68:102], dim=1) > 14).flatten().tolist()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "corrupt_datasets = [count_corrupted_cases(train_dataset), count_corrupted_cases(validation_dataset), count_corrupted_cases(test_dataset)]\n",
    "print(f\"\"\"Corrupted Dataset Indices:\n",
    "    - Training Dataset:   {corrupt_datasets[0]}\n",
    "    - Validation Dataset: {corrupt_datasets[1]}\n",
    "    - Testing Dataset:    {corrupt_datasets[2]}\n",
    "\"\"\")\n",
    "\n",
    "assert len(corrupt_datasets[0]) == 0 and len(corrupt_datasets[1]) == 0 and len(corrupt_datasets[2]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase Datasets Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Phase Dataset\n",
    "phase_datasets = [\n",
    "    DiscardDataset(DATASET_PATH, \n",
    "                   n_rows=34_000, \n",
    "                   years=[2015],\n",
    "                   phase=N,\n",
    "                   balance_data=True,\n",
    "                   discard_type=DiscardDataset.DiscardType.POOL,\n",
    "                   singular=True\n",
    "                  ) \n",
    "    for N in range(3)\n",
    "]\n",
    "\n",
    "\n",
    "phase_dataset_loaders = [\n",
    "    torch.utils.data.DataLoader(phase_dataset, batch_size=1, shuffle=SHUFFLE_DATASET) for phase_dataset in phase_datasets\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round Phase Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_phase_count(ds):\n",
    "    \n",
    "    if ds is None:\n",
    "        return\n",
    "    \n",
    "    pool_counts = ds.x_data[:, 238:374].sum(dim=1)\n",
    "    early = (pool_counts <= 24).sum()\n",
    "    mid = ((24 < pool_counts) & (pool_counts <= 48)).sum()\n",
    "    late = (48 < pool_counts).sum()\n",
    "    \n",
    "    print(f\"Early Phase: {early}\")\n",
    "    print(f\"  Mid Phase: {mid}\")\n",
    "    print(f\" Late Phase: {late}\")\n",
    "    \n",
    "    print(f\"LaTeX: {early:,} & {mid:,} & {late:,}\")\n",
    "    \n",
    "    \n",
    "\n",
    "print(f\"Training Dataset\")\n",
    "round_phase_count(train_dataset)\n",
    "\n",
    "print(f\"\\nValidation Dataset\")\n",
    "round_phase_count(validation_dataset)\n",
    "\n",
    "print(f\"\\nTesting Dataset\")\n",
    "round_phase_count(test_dataset)\n",
    "\n",
    "# Phase Datasets\n",
    "for i, pds in enumerate(phase_datasets):\n",
    "    print(f\"\\nPhase Dataset {i}\")\n",
    "    round_phase_count(pds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Valid Classes Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_counts(dataset, column_name):\n",
    "    n_valid, frequency   = np.unique(torch.sum(dataset.x_data[:, 68:102].bool(), dim=1).numpy(), return_counts=True)\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        \"n_valid_classes\": n_valid,\n",
    "        column_name: frequency\n",
    "    })\n",
    "    data = data.set_index('n_valid_classes')\n",
    "    data = data.reindex(np.arange(0, 14 + 1, dtype=int), fill_value=0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def display_valid_class_distribution(df, count_column, title):\n",
    "    # https://seaborn.pydata.org/generated/seaborn.barplot.html#seaborn.barplot\n",
    "    # http://alanpryorjr.com/visualizations/seaborn/countplot/countplot/\n",
    "    sns.set(style=\"ticks\", font_scale=1)\n",
    "    ax = sns.barplot(data=df,\n",
    "                     x=\"n_valid_classes\", \n",
    "                     y=count_column,\n",
    "                     palette=\"flare\",\n",
    "                     saturation=10,\n",
    "                     edgecolor=(0,0,0),\n",
    "                     linewidth=0,)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of Valid Classes')\n",
    "    plt.ylabel('Counts')\n",
    "    \n",
    "    plt.xticks(range(0, 15))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "inversion_count_df = pd.concat([\n",
    "    get_valid_counts(train_dataset      , \"training_count\"),\n",
    "    get_valid_counts(validation_dataset , \"validation_count\"),\n",
    "    get_valid_counts(test_dataset       , \"testing_count\")], \n",
    "    axis=1).reset_index()\n",
    "\n",
    "display(inversion_count_df)\n",
    "\n",
    "display_valid_class_distribution(inversion_count_df, \"training_count\", 'Valid Class Counts Distribution\\nTraining Dataset')\n",
    "display_valid_class_distribution(inversion_count_df, \"validation_count\", 'Valid Class Counts Distribution\\nValidation Dataset')\n",
    "display_valid_class_distribution(inversion_count_df, \"testing_count\", 'Valid Class Counts Distribution\\nTesting Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_class_distribution(Y, title: str, horizontal=False):\n",
    "    \n",
    "    keys, counts = np.unique(Y, return_counts=True)\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "    bar_list = None\n",
    "    if not horizontal:\n",
    "        bar_list = plt.bar(keys, counts)\n",
    "        plt.xticks(range(34), ticks_tiles_oneline, rotation=90)\n",
    "        plt.ylabel(\"Cases\")\n",
    "    else:\n",
    "        bar_list = plt.barh(keys, counts)\n",
    "        plt.yticks(range(34), ticks_tiles_oneline, rotation=0)\n",
    "        plt.xlabel(\"Cases\")\n",
    "\n",
    "    for i in range(0, 9):\n",
    "        bar_list[i].set_color('r')\n",
    "\n",
    "    for i in range(9, 18):\n",
    "        bar_list[i].set_color('b')\n",
    "\n",
    "    for i in range(18, 27):\n",
    "        bar_list[i].set_color('g')\n",
    "\n",
    "    for i in range(27, 31):\n",
    "        bar_list[i].set_color('y')\n",
    "\n",
    "    for i in range(31, 34):\n",
    "        bar_list[i].set_color('k')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    legend_man = mpatches.Patch(color='r', label='Man')\n",
    "    legend_pin = mpatches.Patch(color='b', label='Pin')\n",
    "    legend_sou = mpatches.Patch(color='g', label='Sou')\n",
    "    legend_wind = mpatches.Patch(color='y', label='Wind')\n",
    "    legend_dragons = mpatches.Patch(color='k', label='Dragon')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(handles=[legend_man, legend_pin, legend_sou, legend_wind, legend_dragons])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "generate_dataset_class_distribution(train_dataset.y_data, \"Training Dataset Class Distribution\", horizontal=False)\n",
    "generate_dataset_class_distribution(validation_dataset.y_data, \"Validation Dataset Class Distribution\", horizontal=False)\n",
    "generate_dataset_class_distribution(test_dataset.y_data, \"Testing Dataset Class Distribution\", horizontal=False)\n",
    "\n",
    "print('PHASE DATASETS')\n",
    "generate_dataset_class_distribution(phase_datasets[0].y_data, \"Early Phase Dataset Class Distribution\", horizontal=False)\n",
    "generate_dataset_class_distribution(phase_datasets[1].y_data, \"Mid Phase Dataset Class Distribution\", horizontal=False)\n",
    "generate_dataset_class_distribution(phase_datasets[2].y_data, \"Late Phase Dataset Class Distribution\", horizontal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_dataset.y_data == 29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\" Simple Feed-Forward Net \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.name = \"BasicDenseNetwork_testing\"\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(11 * 34, 1024)  # SWITCH TO 1024\n",
    "        self.fc2 = torch.nn.Linear(1024, 512)      # SWITCH TO 1024\n",
    "        self.fc3 = torch.nn.Linear(512, 256)\n",
    "        self.fc4 = torch.nn.Linear(256, 128)\n",
    "        self.fc5 = torch.nn.Linear(128, 34)\n",
    "        \n",
    "        self.relu_1 = torch.nn.LeakyReLU()\n",
    "        self.relu_2 = torch.nn.LeakyReLU()\n",
    "        self.relu_3 = torch.nn.LeakyReLU()\n",
    "        self.relu_4 = torch.nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveNet(torch.nn.Module):\n",
    "    \"\"\" Multihead Attention Layer into simple feed-forward net. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AttentiveNet, self).__init__()\n",
    "        \n",
    "        self.name = \"AttentiveNet\"\n",
    "        \n",
    "        self.mha1 = torch.nn.MultiheadAttention(embed_dim=374, \n",
    "                                                num_heads=34,  # 1, 11, or 34 are doable\n",
    "                                                dropout=0.0,   # Default: 0.0.\n",
    "                                                add_zero_attn=True,  # Default: False\n",
    "                                               )\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(11 * 34, 1028)   # SWITCH TO 1024\n",
    "        self.fc2 = torch.nn.Linear(1028, 512)       # SWITCH TO 1024\n",
    "        self.fc3 = torch.nn.Linear(512, 256)\n",
    "        self.fc4 = torch.nn.Linear(256, 128)\n",
    "        self.fc5 = torch.nn.Linear(128, 34)\n",
    "        \n",
    "        self.relu_1 = torch.nn.LeakyReLU()\n",
    "        self.relu_2 = torch.nn.LeakyReLU()\n",
    "        self.relu_3 = torch.nn.LeakyReLU()\n",
    "        self.relu_4 = torch.nn.LeakyReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(1, batch_size, 374)  #  => x.shape[0] = Batch Size\n",
    "        attn_output, attn_output_weights = self.mha1(query=x, key=x, value=x, need_weights=False)  # attn_output_weights = None, if need_weights=False\n",
    "        x = (x * attn_output).reshape(batch_size, 374)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigNet(torch.nn.Module):\n",
    "    \"\"\" Attention Layer into Bigger feed-forward net. \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BigNet, self).__init__()\n",
    "        \n",
    "        self.name = \"BigFeedForward\"\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(11 * 34, 4096)   # EXTRA LAYER\n",
    "        self.fc2 = torch.nn.Linear(4096, 2048)      # EXTRA LAYER\n",
    "        self.fc3 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc4 = torch.nn.Linear(1024, 512)\n",
    "        self.fc5 = torch.nn.Linear(512, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 128)\n",
    "        self.fc7 = torch.nn.Linear(128, 34)\n",
    "        \n",
    "        self.relu_1 = torch.nn.LeakyReLU()\n",
    "        self.relu_2 = torch.nn.LeakyReLU()\n",
    "        self.relu_3 = torch.nn.LeakyReLU()\n",
    "        self.relu_4 = torch.nn.LeakyReLU()\n",
    "        self.relu_5 = torch.nn.LeakyReLU()\n",
    "        self.relu_6 = torch.nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.relu_5(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = self.relu_6(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigAttentionNet(torch.nn.Module):\n",
    "    \"\"\" Attention Layer into Bigger feed-forward net. \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads):\n",
    "        super(BigAttentionNet, self).__init__()\n",
    "        \n",
    "        self.name = f\"MHA-{n_heads}\"\n",
    "        print(self.name)\n",
    "        \n",
    "        self.mha1 = torch.nn.MultiheadAttention(embed_dim=374, \n",
    "                                                num_heads=n_heads,  # 1, 11, or 34 are doable\n",
    "                                                dropout=0.0,   # Default: 0.0.\n",
    "                                                add_zero_attn=False,  # Default: False - Have this false, from not so many experiments, it seems like it slows down learning accuracy by a almost unoticeable bit\n",
    "                                               )\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(11 * 34, 4096)   # EXTRA LAYER\n",
    "        self.fc2 = torch.nn.Linear(4096, 2048)      # EXTRA LAYER\n",
    "        self.fc3 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc4 = torch.nn.Linear(1024, 512)\n",
    "        self.fc5 = torch.nn.Linear(512, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 128)\n",
    "        self.fc7 = torch.nn.Linear(128, 34)\n",
    "        \n",
    "        self.relu_1 = torch.nn.LeakyReLU()\n",
    "        self.relu_2 = torch.nn.LeakyReLU()\n",
    "        self.relu_3 = torch.nn.LeakyReLU()\n",
    "        self.relu_4 = torch.nn.LeakyReLU()\n",
    "        self.relu_5 = torch.nn.LeakyReLU()\n",
    "        self.relu_6 = torch.nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(1, batch_size, 374)  #  => x.shape[0] = Batch Size\n",
    "        attn_output, attn_output_weights = self.mha1(query=x, key=x, value=x, need_weights=False)  # attn_output_weights = None, if need_weights=False\n",
    "        x = (x * attn_output).reshape(batch_size, 374)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.relu_5(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = self.relu_6(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TESTNET(torch.nn.Module):\n",
    "    \"\"\" Attention Layer into Bigger feed-forward net. \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads):\n",
    "        super(TESTNET, self).__init__()\n",
    "        \n",
    "        self.name = f\"MHA-{n_heads}\"\n",
    "        print(self.name)\n",
    "        \n",
    "        self.mha1 = torch.nn.MultiheadAttention(embed_dim=374, \n",
    "                                                num_heads=n_heads,  # 1, 11, or 34 are doable\n",
    "                                                dropout=0.0,   # Default: 0.0.\n",
    "                                                add_zero_attn=False,  # Default: False - Have this false, from not so many experiments, it seems like it slows down learning accuracy by a almost unoticeable bit\n",
    "                                               )\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(11 * 34, 4096)   # EXTRA LAYER\n",
    "        self.fc2 = torch.nn.Linear(4096, 2048)      # EXTRA LAYER\n",
    "        self.fc3 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc4 = torch.nn.Linear(1024, 512)\n",
    "        self.fc5 = torch.nn.Linear(512, 256)\n",
    "        self.fc6 = torch.nn.Linear(256, 128)\n",
    "        self.fc7 = torch.nn.Linear(128, 34)\n",
    "        \n",
    "        self.relu_1 = torch.nn.LeakyReLU()\n",
    "        self.relu_2 = torch.nn.LeakyReLU()\n",
    "        self.relu_3 = torch.nn.LeakyReLU()\n",
    "        self.relu_4 = torch.nn.LeakyReLU()\n",
    "        self.relu_5 = torch.nn.LeakyReLU()\n",
    "        self.relu_6 = torch.nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(3, batch_size, 374)  #  => x.shape[0] = Batch Size\n",
    "        attn_output, attn_output_weights = self.mha1(query=x, key=x, value=x, need_weights=False)  # attn_output_weights = None, if need_weights=False\n",
    "        \n",
    "        breakpoint()\n",
    "        x = (x * attn_output).reshape(batch_size, 374)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu_1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu_2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu_3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        x = self.relu_4(x)\n",
    "        \n",
    "        x = self.fc5(x)\n",
    "        x = self.relu_5(x)\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        x = self.relu_6(x)\n",
    "        \n",
    "        x = self.fc7(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = BigAttentionNet(34).to(DEVICE)  # SWITCH ATTENTION\n",
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)  # Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "loaded_epoch = 0\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "trainable_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FOLDER = None  # Change this to None do NOT want to load anything, otherwise a string to designated model-folder\n",
    "\n",
    "# TO LOAD OR NOT LOAD\n",
    "if LOAD_FOLDER:\n",
    "    CHECKPOINT_PATH = Path('model_checkpoints') / LOAD_FOLDER\n",
    "    DESCRIPTION_PATH = CHECKPOINT_PATH / 'description.json'\n",
    "    SUMMARY_PATH = CHECKPOINT_PATH / 'summary.csv'\n",
    "    INVERSION_STATS_PATH = CHECKPOINT_PATH / 'inversions.csv'\n",
    "    INVERSION_COUNTS_PATH = CHECKPOINT_PATH / 'inversions_counts.csv'\n",
    "    HEATMAP_PATH = CHECKPOINT_PATH / 'heatmap.csv'\n",
    "\n",
    "    last_epoch_file = sorted([c for c in CHECKPOINT_PATH.iterdir() if c.suffix == '.pt'])[-1]\n",
    "    loaded_checkpoint = torch.load(last_epoch_file)\n",
    "    print('Loaded Epoch', loaded_checkpoint['epoch'])\n",
    "\n",
    "    model.load_state_dict(loaded_checkpoint['model_state'])\n",
    "    optimizer.load_state_dict(loaded_checkpoint['optimizer_state'])\n",
    "    loaded_epoch = loaded_checkpoint['epoch']\n",
    "\n",
    "else:\n",
    "    # Create Model Checkpoint Folder\n",
    "    timestamp_string = time.strftime('%Y-%m-%d_%H-%M', time.localtime(time.time()))\n",
    "    CHECKPOINT_PATH = Path('model_checkpoints') / f\"{timestamp_string}_{model.name}\"\n",
    "    CHECKPOINT_PATH.mkdir()\n",
    "\n",
    "    DESCRIPTION_PATH = CHECKPOINT_PATH / 'description.json'\n",
    "    SUMMARY_PATH = CHECKPOINT_PATH / 'summary.csv'\n",
    "    INVERSION_STATS_PATH = CHECKPOINT_PATH / 'inversions.csv'\n",
    "    INVERSION_COUNTS_PATH = CHECKPOINT_PATH / 'inversions_counts.csv'\n",
    "    HEATMAP_PATH = CHECKPOINT_PATH / 'heatmap.csv'\n",
    "\n",
    "    model_desc_json = {\n",
    "        'model_name': model.name,\n",
    "        'model_description': repr(model),\n",
    "        'dataset_config': repr(selected_config)\n",
    "    }\n",
    "\n",
    "    with open(DESCRIPTION_PATH, 'w') as outfile:\n",
    "        json.dump(model_desc_json, outfile)\n",
    "\n",
    "    with open(SUMMARY_PATH, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"epoch\", \n",
    "                         \"train_loss\", \n",
    "                         \"train_acc\", \n",
    "                         \"train_average_valid_weight_sum\", \n",
    "                         \"train_average_weight_per_valid_class\", \n",
    "                         \"train_average_weight_per_invalid_class\", \n",
    "                         \"val_loss\", \n",
    "                         \"val_acc\", \n",
    "                         \"val_average_valid_weight_sum\", \n",
    "                         \"val_average_weight_per_valid_class\", \n",
    "                         \"val_average_weight_per_invalid_class\",\n",
    "                         \"time_elapsed\"])\n",
    "    \n",
    "    with open(INVERSION_STATS_PATH, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"mode\",\n",
    "                         \"epoch\",\n",
    "                         \"n_valid\",\n",
    "                         \"min\", \n",
    "                         \"max\", \n",
    "                         \"mean\", \n",
    "                         \"median\",])\n",
    "        \n",
    "    inversion_count_df.to_csv(INVERSION_COUNTS_PATH, index=False)\n",
    "    \n",
    "    with open(HEATMAP_PATH, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        heatmap_fieldnames = [\"mode\", \"epoch\", \"n_valid\"] + [f'h_{i}' for i in range(34)]\n",
    "        writer.writerow(heatmap_fieldnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING & VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_hhmmss(s):\n",
    "    seconds = s\n",
    "    minutes = seconds // 60\n",
    "    hours = minutes // 60\n",
    "    return \"%02d:%02d:%02d\" % (hours, minutes % 60, seconds % 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discard_weight_sum_metrics(hands, logits):\n",
    "    \"\"\" \n",
    "    Calculates different weight sum metrics.\n",
    "    Note: TensorShape of both params must be equal!\n",
    "\n",
    "    Args:\n",
    "        hands (Tensor): POV hands as tensor. Expected shape: [b, 34] where b is batch size\n",
    "        logits (Tensor): logits as tensor. Expected shape: [b, 34] where b is batch size\n",
    "\n",
    "    Returns:\n",
    "        tuple(Float, Float): \n",
    "            0. First value is the average weight sum of valid discards.\n",
    "            1. Second value is the average weight sum of valid discards divided by number of valid discard classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_distributions = F.softmax(logits, dim=1)  # Convert logits into distribution that sums to 1\n",
    "    masked = hands.bool() * class_distributions  # Mask tensorwise, where invalid classes => 0.\n",
    "    num_valid_classes = torch.sum(hands.bool(), dim=1)\n",
    "    sum_valid_weight_sum = torch.sum(masked, dim=1)  # Sum() each row\n",
    "\n",
    "    # Batch Averages\n",
    "    avg_batch_weight_sum = torch.mean(sum_valid_weight_sum).item()\n",
    "    avg_batch_weight_sum_per_class = torch.mean(sum_valid_weight_sum / num_valid_classes).item()\n",
    "    avg_batch_weight_sum_per_class_invalid = torch.mean((1 - sum_valid_weight_sum) / (34 - num_valid_classes)).item()\n",
    "    \n",
    "    return avg_batch_weight_sum, avg_batch_weight_sum_per_class, avg_batch_weight_sum_per_class_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sorted_binary_valid_class_tensors(hands, logits):\n",
    "    return torch.gather(hands.bool(), dim=1, index=torch.argsort(logits, dim=1, descending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inversion_rows(mode: str, epoch: int, n_valids: np.array, binary_valids: np.array) -> list:\n",
    "    \n",
    "    assert mode == 'training' or mode == 'validation', f\"ILLEGAL MODE: {mode}\"\n",
    "    \n",
    "    # Count Inversions Formula\n",
    "    # all_inversion_counts = torch.sum(\n",
    "    #    torch.cumsum(binary_valids.bitwise_not(), dim=1) * binary_valids, \n",
    "    #    dim=1\n",
    "    # )\n",
    "    \n",
    "    # Conversion: [Tensor -> np.array] Reason: Removes overhead from GPU memory TODO: NO NEED AS WE WILL DO THE CONVERSION OUTSIDE\n",
    "#     n_valids = n_valids.cpu().numpy()  \n",
    "#     binary_valids = binary_valids.cpu().numpy()\n",
    "    \n",
    "    all_inversion_counts = (np.bitwise_not(binary_valids).cumsum(axis=1) * binary_valids).sum(axis=1)  # Count inversions of binary arrays\n",
    "    \n",
    "    inversion_dict_list = []\n",
    "    for n_valid in range(1, 15):\n",
    "        mask = n_valids == n_valid\n",
    "        if True in mask:  # False if mask does not find matching tensors\n",
    "            arr = all_inversion_counts[mask]  # Masked inversion counts tensor      \n",
    "            inversion_dict_list.append({\n",
    "                 \"mode\": 0 if mode == 'training' else 1,\n",
    "                 \"epoch\": epoch,\n",
    "                 \"n_valid\": n_valid,\n",
    "                 \"min\": np.amin(arr), \n",
    "                 \"max\": np.amax(arr), \n",
    "                 \"mean\": np.mean(arr), \n",
    "                 \"median\": np.median(arr),\n",
    "            })\n",
    "        else:\n",
    "            inversion_dict_list.append({\n",
    "                 \"mode\": 0 if mode == 'training' else 1,\n",
    "                 \"epoch\": epoch,\n",
    "                 \"n_valid\": n_valid,\n",
    "                 \"min\": np.NAN, \n",
    "                 \"max\": np.NAN, \n",
    "                 \"mean\": np.NAN, \n",
    "                 \"median\": np.NAN,\n",
    "            })\n",
    "\n",
    "    return inversion_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_rows(mode: str, epoch: int, n_valids: np.array, binary_valids: np.array) -> np.array:\n",
    "    \n",
    "    assert mode == 'training' or mode == 'validation', f\"ILLEGAL MODE: {mode}\"\n",
    "    \n",
    "    # Heat-values setup\n",
    "    heat_array = np.full((14, 34), fill_value=np.NAN)  # 2D np.array\n",
    "    for n_valid in range(1, 15):\n",
    "        mask = n_valids == n_valid\n",
    "        if True in mask:  # False if mask does not find matching tensors\n",
    "            masked_arrays = binary_valids[mask, :]\n",
    "            heat_array[n_valid - 1] = np.sum(masked_arrays, axis=0) / masked_arrays.shape[0]  # Get average frequency of valid bit for each position\n",
    "    \n",
    "    # Metadata columns\n",
    "    mode_column = np.zeros((14, 1), dtype=np.uint8) if mode == 'training' else np.ones((14, 1), dtype=np.uint8)\n",
    "    epoch_column = np.full((14, 1), fill_value=epoch)\n",
    "    n_valid_column = np.arange(start=1, stop=15, dtype=np.uint8).reshape(14, 1)\n",
    "    \n",
    "    return np.concatenate((mode_column, epoch_column, n_valid_column, heat_array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loaded_epoch != 0:\n",
    "    loaded_epoch += 1  # If epoch was loaded\n",
    "    \n",
    "# Print Dataset Discard Format\n",
    "print(\"Training Dataset Discard-Format:   {}\".format(train_dataset.discard_type))\n",
    "print(\"Validation Dataset Discard-Format: {}\".format(validation_dataset.discard_type))\n",
    "print(\"Test Dataset Discard-Format:       {}\".format(test_dataset.discard_type))\n",
    "\n",
    "# Progress Bars\n",
    "mq = trange(EPOCHS, desc='EPOCH', unit='epoch', initial=loaded_epoch)\n",
    "tq = trange(len(train_loader), desc=f'TRAINING', unit='batch', mininterval=0.5)\n",
    "vq = trange(len(validation_loader), desc=f'VALIDATION', unit='batch')\n",
    "\n",
    "\n",
    "for epoch in range(loaded_epoch, EPOCHS):\n",
    "    \n",
    "    torch.manual_seed(epoch)\n",
    "    start_timer = timer()  # Start timer\n",
    "    \n",
    "    ##############################################\n",
    "    # TRAINING\n",
    "    ##############################################\n",
    "    sum_epoch_loss = 0.0\n",
    "    sum_epoch_acc = 0.0\n",
    "    sum_valid_discard_weight_sum = 0.0\n",
    "    sum_valid_discard_weight_sum_per_tile = 0.0\n",
    "    sum_invalid_discard_weight_sum_per_tile = 0.0\n",
    "\n",
    "    binary_valid_tensors = []  # For Inversion & Heatmap calculation\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        X = batch['X'].to(DEVICE)\n",
    "        y = batch['y'].to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(X)  # Outputs float values for each class (do softmax on `outputs` to get distribution)\n",
    "        \n",
    "        # Loss Calculation\n",
    "        loss = criterion(outputs, y)  # avg loss in batch -> No need for softmax if criterion = Cross Entropy Loss\n",
    "        sum_epoch_loss += loss.item()\n",
    "\n",
    "        # Accuracy Calculation\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        num_correct_predictions = torch.sum(torch.eq(predictions, y)).item()\n",
    "        batch_acc = num_correct_predictions / y.shape[0]  # y.shape[0] = batch_size\n",
    "        sum_epoch_acc += batch_acc\n",
    "        \n",
    "        # Calculate Valid/Invalid Discards weights\n",
    "        avg_vwsum, avg_vwsum_per_class, avg_iwsum_per_class = get_discard_weight_sum_metrics(hands=X[:, 68:102], logits=outputs)\n",
    "        sum_valid_discard_weight_sum += avg_vwsum  # Mean() each row into final `valid weight average`\n",
    "        sum_valid_discard_weight_sum_per_tile += avg_vwsum_per_class\n",
    "        sum_invalid_discard_weight_sum_per_tile += avg_iwsum_per_class\n",
    "        \n",
    "        # Calculate Number of Inversios\n",
    "        binary_valid_tensors.append(generate_sorted_binary_valid_class_tensors(hands=X[:, 68:102], logits=outputs))\n",
    "\n",
    "        # Batch Clean-up\n",
    "        loss.backward()  # compute gradients\n",
    "        optimizer.step()  # update weights\n",
    "        \n",
    "        tq.update(1)\n",
    "        \n",
    "    tq.refresh()\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    # Training Summary Calculations\n",
    "    avg_acc_train = sum_epoch_acc / len(train_loader)  # average accuracy\n",
    "    avg_loss_train = sum_epoch_loss / len(train_loader)  # average loss\n",
    "    avg_valid_discard_weight_sum_train = sum_valid_discard_weight_sum / len(train_loader)  # average valid weight\n",
    "    sum_valid_discard_weight_sum_per_tile_train = sum_valid_discard_weight_sum_per_tile / len(train_loader)\n",
    "    sum_invalid_discard_weight_sum_per_tile_train = sum_invalid_discard_weight_sum_per_tile / len(train_loader)\n",
    "    \n",
    "    ### INVERSION & HEATMAP Calculation\n",
    "    binary_valid_tensors = torch.cat(binary_valid_tensors).cpu().numpy()  # Nested 2D PyTorch Tensors => Single 2D NumPy Array\n",
    "    n_valid_classes = binary_valid_tensors.sum(axis=1)\n",
    "    inversion_rows_train = generate_inversion_rows('training', epoch, n_valid_classes, binary_valid_tensors)\n",
    "    heatmap_rows_train = generate_heatmap_rows('training', epoch, n_valid_classes, binary_valid_tensors)\n",
    "        \n",
    "    ##############################################\n",
    "    # VALIDATION\n",
    "    ##############################################\n",
    "    sum_epoch_loss = 0.0\n",
    "    sum_epoch_acc = 0.0\n",
    "    sum_valid_discard_weight_sum = 0.0\n",
    "    sum_valid_discard_weight_sum_per_tile = 0.0\n",
    "    sum_invalid_discard_weight_sum_per_tile = 0.0\n",
    "    \n",
    "    binary_valid_tensors = []  # For Inversion & Heatmap calculation\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, batch in enumerate(validation_loader):\n",
    "        X = batch['X'].to(DEVICE)\n",
    "        y = batch['y'].to(DEVICE)\n",
    "\n",
    "        # optimizer.zero_grad()  # TODO: Needed?\n",
    "\n",
    "        with torch.no_grad():  # Disables tracking of gradient\n",
    "            outputs = model(X)\n",
    "            \n",
    "        # Loss Calculation\n",
    "        loss = criterion(outputs, y)  # avg loss in batch\n",
    "        sum_epoch_loss += loss.item()\n",
    "\n",
    "        # Accuracy Calculation\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        num_correct_predictions = torch.sum(torch.eq(predictions, y)).item()\n",
    "        batch_acc = num_correct_predictions / y.shape[0]  # y.shape[0] = batch_size\n",
    "        sum_epoch_acc += batch_acc\n",
    "        \n",
    "        # Calculate Valid/Invalid Discards weights\n",
    "        avg_vwsum, avg_vwsum_per_class, avg_iwsum_per_class = get_discard_weight_sum_metrics(hands=X[:, 68:102], logits=outputs)\n",
    "        sum_valid_discard_weight_sum += avg_vwsum  # Mean() each row into final `valid weight average`\n",
    "        sum_valid_discard_weight_sum_per_tile += avg_vwsum_per_class\n",
    "        sum_invalid_discard_weight_sum_per_tile += avg_iwsum_per_class\n",
    "        \n",
    "        # Calculate Number of Inversions\n",
    "        binary_valid_tensors.append(generate_sorted_binary_valid_class_tensors(hands=X[:, 68:102], logits=outputs))\n",
    "        \n",
    "        vq.update(1)\n",
    "    \n",
    "    vq.refresh()\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    # Training Summary Calculations\n",
    "    avg_acc_val = sum_epoch_acc / len(validation_loader)  # average accuracy\n",
    "    avg_loss_val = sum_epoch_loss / len(validation_loader)  # average loss\n",
    "    avg_valid_discard_weight_sum_val = sum_valid_discard_weight_sum / len(validation_loader)  # average valid weight\n",
    "    sum_valid_discard_weight_sum_per_tile_val = sum_valid_discard_weight_sum_per_tile / len(validation_loader)\n",
    "    sum_invalid_discard_weight_sum_per_tile_val = sum_invalid_discard_weight_sum_per_tile / len(validation_loader)\n",
    "    \n",
    "    ### INVERSION & HEATMAP Calculation\n",
    "    binary_valid_tensors = torch.cat(binary_valid_tensors).cpu().numpy()  # Nested 2D PyTorch Tensors => Single 2D NumPy Array\n",
    "    n_valid_classes = binary_valid_tensors.sum(axis=1)\n",
    "    inversion_rows_val = generate_inversion_rows('validation', epoch, n_valid_classes, binary_valid_tensors)\n",
    "    heatmap_rows_val = generate_heatmap_rows('validation', epoch, n_valid_classes, binary_valid_tensors)\n",
    "    \n",
    "    ##############################################\n",
    "    # EPOCH CLEAN-UP\n",
    "    ##############################################\n",
    "    elapsed_time = timer() - start_timer  # End Timer\n",
    "    \n",
    "    # Print Epoch Summary\n",
    "    print('EPOCH {:>2}  |  TRAIN: loss={:.3f}, acc={:5.3f}, vwsum={:5.3f} -> valid/invalid={:5.3f}/{:5.3f} |  VALIDATION: loss={:.3f}, acc={:5.3f}, vwsum={:5.3f} -> valid/invalid={:5.3f}/{:5.3f}  | TIME ELAPSED: {}'\n",
    "          .format(epoch,\n",
    "                  avg_loss_train, \n",
    "                  avg_acc_train,\n",
    "                  avg_valid_discard_weight_sum_train,\n",
    "                  sum_valid_discard_weight_sum_per_tile_train,\n",
    "                  sum_invalid_discard_weight_sum_per_tile_train,\n",
    "                  avg_loss_val, \n",
    "                  avg_acc_val,\n",
    "                  avg_valid_discard_weight_sum_val,\n",
    "                  sum_valid_discard_weight_sum_per_tile_val,\n",
    "                  sum_invalid_discard_weight_sum_per_tile_val,\n",
    "                  seconds_to_hhmmss(elapsed_time),\n",
    "                 ))\n",
    "    \n",
    "    # Save Epoch Summary to csv\n",
    "    with open(SUMMARY_PATH, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\n",
    "            epoch, \n",
    "            avg_loss_train,\n",
    "            avg_acc_train,\n",
    "            avg_valid_discard_weight_sum_train,\n",
    "            sum_valid_discard_weight_sum_per_tile_train,\n",
    "            sum_invalid_discard_weight_sum_per_tile_train,\n",
    "            avg_loss_val,\n",
    "            avg_acc_val,\n",
    "            avg_valid_discard_weight_sum_val,\n",
    "            sum_valid_discard_weight_sum_per_tile_val,\n",
    "            sum_invalid_discard_weight_sum_per_tile_val,\n",
    "            seconds_to_hhmmss(elapsed_time)\n",
    "        ])\n",
    "        \n",
    "    with open(INVERSION_STATS_PATH, 'a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=[\"mode\",\"epoch\",\"n_valid\",\"min\", \"max\", \"mean\", \"median\",])\n",
    "        writer.writerows(inversion_rows_train + inversion_rows_val)\n",
    "    \n",
    "    # Heatmap to .csv\n",
    "    heatmap_combined_np = np.concatenate((heatmap_rows_train, heatmap_rows_val), axis=0)\n",
    "    heatmap_df = pd.DataFrame(heatmap_combined_np)\n",
    "    heatmap_df.to_csv(HEATMAP_PATH, mode='a', header=False, index=False, na_rep='NaN')\n",
    "        \n",
    "    # Checkpoint Creation\n",
    "    training_checkpoint = {\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'epoch': epoch,\n",
    "    }\n",
    "\n",
    "    destination = CHECKPOINT_PATH / (f'epoch-{epoch:03}.pt')\n",
    "    torch.save(training_checkpoint, destination)\n",
    "    \n",
    "    # Progress Bar Clean-up\n",
    "    mq.update(1)\n",
    "    tq.reset()\n",
    "    vq.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD_MODEL_FOLDER = \"MHA-1-SUPHX-2021-05-13\"          # 15 000 000 Training\n",
    "# LOAD_MODEL_FOLDER = \"MHA-34-POOL-NEW-2021-05-11\"      # 34 000 000 Training\n",
    "LOAD_MODEL_FOLDER = \"MHA-34-POOL-BALANCED-2021-05-08\" # 34 000 000 Training\n",
    "\n",
    "LOAD_EPOCH_NUMBER = None  # If None, select epoch with lowest val_loss\n",
    "\n",
    "CHECKPOINT_PATH = Path('model_checkpoints') / LOAD_MODEL_FOLDER\n",
    "DESCRIPTION_PATH = CHECKPOINT_PATH / 'description.json'\n",
    "SUMMARY_PATH = CHECKPOINT_PATH / 'summary.csv'\n",
    "INVERSION_STATS_PATH = CHECKPOINT_PATH / 'inversions.csv'\n",
    "INVERSION_COUNTS_PATH = CHECKPOINT_PATH / 'inversions_counts.csv'\n",
    "HEATMAP_PATH = CHECKPOINT_PATH / 'heatmap.csv'\n",
    "\n",
    "loaded_checkpoint = None\n",
    "if not LOAD_EPOCH_NUMBER:\n",
    "    summary_df = pd.read_csv(SUMMARY_PATH).dropna()\n",
    "    lowest_val_loss_id = summary_df['val_loss'].idxmin()\n",
    "    loaded_checkpoint = torch.load(CHECKPOINT_PATH / f\"epoch-{lowest_val_loss_id:03}.pt\")\n",
    "else:\n",
    "    loaded_checkpoint = torch.load(CHECKPOINT_PATH / f\"epoch-{LOAD_EPOCH_NUMBER:03}.pt\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = BigAttentionNet(1).to(DEVICE)  # SWITCH ATTENTION\n",
    "# model = BigNet().to(DEVICE)\n",
    "model.load_state_dict(loaded_checkpoint['model_state'])\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(DEVICE)  # Loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "optimizer.load_state_dict(loaded_checkpoint['optimizer_state'])\n",
    "loaded_epoch = loaded_checkpoint['epoch']\n",
    "\n",
    "for k, v in json.load(DESCRIPTION_PATH.open()).items():\n",
    "    print(f\"{k}: \\n{v}\\n\")\n",
    "\n",
    "    print('Loaded Epoch', loaded_checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTESTING')\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "targets = []\n",
    "\n",
    "pov_hands = []  # 2d list\n",
    "\n",
    "# sorted_output_logits = []\n",
    "output_logits = []\n",
    "\n",
    "\n",
    "# Confidence metric: We track how far away the correct guess was from prediction.\n",
    "# prediction_indices = []  # List of indices of correct target in list of predicted output values. Optimally should only contain 0s. List of indices between [0, 33] # RENAMED TO CORRECT_INDICES\n",
    "\n",
    "# sorted_prediction_indices = []\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, batch in enumerate(tqdm(test_loader, total=len(test_loader), desc=f'Testing', unit='batch')):\n",
    "#     print(X.shape)\n",
    "#     breakpoint()\n",
    "    X = batch['X'].to(DEVICE)\n",
    "#     X = torch.arange(3 * 374).reshape(1, 3, 374).float().to(DEVICE)\n",
    "    y = batch['y'].to(DEVICE)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        output = model(X)\n",
    "    \n",
    "    output = output[0]  # output is shape[1, 34] due to batching process, this line undoes it to shape[34]\n",
    "    \n",
    "    output_logits.append(output)\n",
    "    pov_hands.append(X[0][68:102])\n",
    "    targets.append(y.item())\n",
    "\n",
    "\n",
    "sorted_logits, sorted_logits_indices = torch.sort(torch.vstack(output_logits), descending=True)  # sorted_logits_indices = sorted_prediction_indices\n",
    "correct_indices = [c.index(targets[i]) for i, c in enumerate(sorted_logits_indices.tolist())]\n",
    "predictions = [p[0].item() for p in sorted_logits_indices]  # Creation of predictions list (deferred for optimization)\n",
    "\n",
    "print('Testing Completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top K Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### BALANCED Singular GAO Dataset (68 000)\n",
    "MHA-34-POOL-NEW-2021-05-11:  (Training: 34 000 000)\n",
    "- Top  1 :  0.669\n",
    "- Top  2 :  0.858\n",
    "- Top  3 :  0.929\n",
    "\n",
    "MHA-34-POOL-BALANCED-2021-05-08:  (Training: 34 000 000)\n",
    "- Top  1 :  0.671\n",
    "- Top  2 :  0.857\n",
    "- Top  3 :  0.930\n",
    "\n",
    "MHA-1-SUPHX-2021-05-13 **EPOCH 16**: (Training: 15 000 000)\n",
    "- Top  1 :  0.647\n",
    "- Top  2 :  0.841\n",
    "- Top  3 :  0.918\n",
    "\n",
    "\n",
    "#### IMBALANCED Singular GAO Dataset (68 000)\n",
    "\n",
    "MHA-34-POOL-NEW-2021-05-11\n",
    "- Top  1 :  0.670\n",
    "- Top  2 :  0.865\n",
    "- Top  3 :  0.935\n",
    "\n",
    "MHA-34-POOL-BALANCED-2021-05-08\n",
    "- Top  1 :  0.669\n",
    "- Top  2 :  0.863\n",
    "- Top  3 :  0.934\n",
    "\n",
    "MHA-1-SUPHX-2021-05-13\n",
    "- Top  1 :  0.655\n",
    "- Top  2 :  0.853\n",
    "- Top  3 :  0.926"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_correctness = Counter()  # 0 = perfect predictions, 33 = worst prediction case\n",
    "\n",
    "assert len(targets) == len(sorted_logits_indices)\n",
    "\n",
    "for index_of_prediction in correct_indices:\n",
    "    prediction_correctness[index_of_prediction] += 1\n",
    "    \n",
    "# Accuracy of Top Predictions\n",
    "for i in range(34):\n",
    "    top_sum = 0\n",
    "    for j in range(i + 1):\n",
    "        top_sum += prediction_correctness[j]\n",
    "    \n",
    "    print(f\"Top {i+1:>2} : {top_sum / len(targets):6.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "title_fontsize = 17\n",
    "ticks_fontsize = 12\n",
    "label_fontsize = 15\n",
    "legend_fontsize = 13\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.bar(prediction_correctness.keys(), [v / len(targets) for v in prediction_correctness.values()])\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.xlim(-1, 34)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, 0.1), fontsize=ticks_fontsize)\n",
    "plt.xticks(range(34), fontsize=ticks_fontsize)\n",
    "\n",
    "plt.title('Correct Prediction Distribution', fontsize=title_fontsize)\n",
    "plt.xlabel('Index of predicted target\\n\\n(0 = perfect prediction, 1 = next prediction was correct, etc.)', fontsize=label_fontsize)\n",
    "plt.ylabel('Percentage of predictions', fontsize=label_fontsize)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Invalid Discards Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_discards_dict = {}\n",
    "hand_tensor = torch.vstack(pov_hands).to(DEVICE)\n",
    "for top_index in range(0, 34):\n",
    "    top_N_mask = sorted_logits_indices[:, top_index].reshape(-1, 1)  # Column with current selected indices rowise\n",
    "    found_values = hand_tensor.gather(dim=1, index=top_N_mask)\n",
    "    invalid_discards_dict[top_index] = torch.sum(found_values == 0)\n",
    "    \n",
    "# Accuracy of Top Predictions\n",
    "total_invalid_discards = sum(invalid_discards_dict.values()).item()\n",
    "print(\"TOTAL INVALID DISCARDS:\", total_invalid_discards)\n",
    "print(\"Top K Accumulated Invalid Discards\")\n",
    "for i in range(34):\n",
    "    top_sum = 0\n",
    "    for j in range(i + 1):\n",
    "        top_sum += invalid_discards_dict[j]\n",
    "    \n",
    "    print(\"Top {:>2}: {:>7.5f}  {:>8}  (+{:>7})\".\n",
    "          format(i+1,\n",
    "                 top_sum / total_invalid_discards,\n",
    "                 top_sum,\n",
    "                 invalid_discards_dict[i]\n",
    "                ))\n",
    "\n",
    "print(\"\\nTop 1 Summary:\")\n",
    "print(\"- Number of Invalid Discard Prediction: {}\".format(invalid_discards_dict[0]))\n",
    "print(\"- In {} out of {} test cases, or {:.3f}% of all cases, an invalid class was predicted.\".format(invalid_discards_dict[0], len(targets), (invalid_discards_dict[0] / len(targets)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid / Invalid Discard Weight Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Valid Tiles vs Valid Classes\n",
    "An important note is that we should be mindful about the subtle difference between valid **tiles** vs valid **classes**.\n",
    "A given hand can be in this format: \n",
    "```python\n",
    "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    " 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n",
    "```\n",
    "Note that there's 2 tiles of class `21`. \n",
    "In this example:\n",
    "- number of **valid tiles**   = 11\n",
    "- number of **valid classes** = 10\n",
    "\n",
    "**Note:** The number of **valid tiles** >= The number of **valid classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand_tensor = torch.vstack(pov_hands).to(DEVICE)\n",
    "logits_tensor = torch.vstack(output_logits).to(DEVICE)\n",
    "avg_ws, avg_ws_valid, avg_ws_invalid = get_discard_weight_sum_metrics(hand_tensor, logits_tensor)\n",
    "\n",
    "valid_tiles = torch.sum(hand_tensor, dim=1)\n",
    "avg_valid_tiles = torch.mean(valid_tiles.float()).item()\n",
    "\n",
    "valid_classes = torch.sum(hand_tensor.bool(), dim=1)\n",
    "avg_valid_classes = torch.mean(valid_classes.float()).item()\n",
    "\n",
    "print(f'Average Valid Weight Sum:             {avg_ws:>6.3f}')\n",
    "print(f'Average Weight Sum per Valid Class:   {avg_ws_valid:>6.3f}')\n",
    "print(f'Average Weight Sum per Invalid Class: {avg_ws_invalid:>6.3f}')\n",
    "print(f'Average Number of Valid Tiles:        {avg_valid_tiles:>6.3f}')\n",
    "print(f'Average Number of Valid Classes:      {avg_valid_classes:>6.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More elaborated accuracy metric\n",
    "- Check if any of top 3 predictions are correct.\n",
    "- Check if any of the predictions prioritized above target are invalid discards.\n",
    "    - Note that this only applies if target is not top 1 predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Confidence Distribution\n",
    "Aka. \"Average Prediction Weight Density\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_output_distribution = F.softmax(sorted_logits, dim=1)\n",
    "numpy_distribution = sorted_output_distribution.cpu().detach().numpy()\n",
    "avg_distribution = np.mean(numpy_distribution, axis=0)\n",
    "\n",
    "print(\"Top K Propability Confidence Distribution\")\n",
    "for i in range(34):\n",
    "    top_sum = 0\n",
    "    for j in range(i + 1):\n",
    "        top_sum += avg_distribution[j]\n",
    "    \n",
    "    print(f\"Top {i+1:>2}: {top_sum:>8.3f}  (+{avg_distribution[i]:>5.3f})\")\n",
    "    \n",
    "print(\"\\nOn average, the top 1 prediction is allocated {:>5.2f}% of total probability.\".format(avg_distribution[0] * 100))\n",
    "print(\"On average, the top 3 predictions are allocated {:>5.2f}% of total probability.\".format(sum(avg_distribution[[0,1,2]]) * 100))\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.bar(range(34), avg_distribution)\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0.0, 1.0, 0.1))\n",
    "plt.xticks(range(34))\n",
    "\n",
    "plt.title('Probability Confidence Distribution')\n",
    "plt.xlabel('Prediction Priority')\n",
    "plt.ylabel('Average Weight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score and Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add Target names for better looking table: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html\n",
    "print(sklearn.metrics.classification_report(targets, predictions, digits=3, zero_division=1, target_names=ticks_tiles_oneline))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various Graphs and Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset_class_distribution(test_dataset.y_data, \"Testing Dataset Class Distribution\", horizontal=False)\n",
    "generate_dataset_class_distribution(predictions, \"Prediction Class Distribution\", horizontal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenated Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_0, counts_0 = np.unique(test_dataset.y_data, return_counts=True)\n",
    "keys_1, counts_1 = np.unique(predictions, return_counts=True)\n",
    "\n",
    "fig = plt.figure(figsize=(17, 10))\n",
    "\n",
    "df1 = pd.DataFrame({'classes':keys_0, 'cases':counts_0})\n",
    "df2 = pd.DataFrame({'classes':keys_1, 'cases':counts_1})\n",
    "\n",
    "df1['source'] = \"Actual\"\n",
    "df2['source'] = \"Predicted\"\n",
    "\n",
    "res=pd.concat([df1, df2])\n",
    "\n",
    "sns.barplot(x='classes',y='cases', data=res, hue='source')\n",
    "plt.xticks(range(34), ticks_tiles_oneline, rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_nparray = sklearn.metrics.confusion_matrix(targets, predictions, normalize='true')\n",
    "df_cm = pd.DataFrame(confusion_nparray)\n",
    "plt.figure(figsize=(14, 13))\n",
    "sns.set(font_scale=1) # for label size\n",
    "sns.heatmap(\n",
    "    df_cm, \n",
    "    annot=False, \n",
    "    annot_kws={\"size\": 10}, square=True, \n",
    "    xticklabels=ticks_tiles_oneline, \n",
    "    yticklabels=ticks_tiles_oneline,\n",
    "    vmin=0, vmax=1,\n",
    "    center=0.5,\n",
    "#     vmin=0, vmax=1,\n",
    "    cbar_kws=dict(shrink=0.5, label='Percentage', )\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilities.tiles as tc\n",
    "\n",
    "def pretty_print_x(x):\n",
    "    \n",
    "    def get_wind(value):\n",
    "        if value == 0:\n",
    "            return 'EAST'\n",
    "        elif value == 1:\n",
    "            return 'SOUTH'\n",
    "        elif value == 2:\n",
    "            return 'WEST'\n",
    "        else:\n",
    "            return 'NORTH' \n",
    "    \n",
    "    if isinstance(x, torch.Tensor):\n",
    "        x = [int(n) for n in x.tolist()]\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        x = [int(n) for n in x.tolist()]\n",
    "\n",
    "    round_wind = get_wind(x[0])\n",
    "    dealer = get_wind(x[1])\n",
    "    player = get_wind(x[2])\n",
    "\n",
    "    print(f\"Round Wind       = {round_wind}\")\n",
    "    print(f\"Dealer           = {dealer}\")\n",
    "    print(f\"POV Player       = {player}\")\n",
    "    print()\n",
    "    print(f\"Honba / Riichi Count = {int(x[3])} / {int(x[4])}\")\n",
    "#     print(f\"Riichi Count     = {int(x[4])}\")\n",
    "#     print()\n",
    "    print(f\"Wall Tiles left  = {int(x[5])}\")\n",
    "\n",
    "#     print()\n",
    "#     for i in range(4):\n",
    "#         print(f\"P{i} Score         = {int(x[6 + i]) * 1000}\")\n",
    "\n",
    "#     print()\n",
    "    print(\"Score =\\t [ {} / {} / {} / {} ]\".format(*(int(x[6 + i]) * 1000 for i in range(4))))\n",
    "\n",
    "    print(\"Riichi Status =\\t [{}-{}-{}-{}]\".format(*(x[10 + i] for i in range(4))))\n",
    "#     for i in range(4):\n",
    "#         print(f\"P{i} Riichi Status = {bool(x[10 + i])}\")\n",
    "\n",
    "    # TILES\n",
    "    to_tiles = lambda l: tc.TilesConverter.to_one_line_string(tc.TilesConverter.to_136_array(l))\n",
    "\n",
    "    print()\n",
    "    print(f\"Dora Indicators = {to_tiles(x[34:68])}\")\n",
    "    print()\n",
    "    print(f\"POV Hand        = {to_tiles(x[68:102])}\")\n",
    "    print()\n",
    "    for i in range(4):\n",
    "        print(f\"P{i} Melds        = {to_tiles(x[102 + (34 * i):136 + (34 * i)])}\")\n",
    "\n",
    "    print()\n",
    "    for i in range(4):\n",
    "        print(f\"P{i} Pools        = {to_tiles(x[238 + (34 * i):272 + (34 * i)])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index and Attention Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_heatmap(input_array: np.array, title=None, cbar=True, color_scheme='white', grid_color='black'):\n",
    "    \n",
    "    annot_fontsize = 13\n",
    "    tick_fontsize = 14\n",
    "\n",
    "    \n",
    "    assert color_scheme in ['white', 'attention', 'plain']\n",
    "        \n",
    "    assert (input_array.shape[0] == 11 or input_array.shape[0] == 15) and input_array.shape[1] == 34\n",
    "    is_11x34_data = input_array.shape[0] == 11\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7), sharex='col', gridspec_kw={'width_ratios':[120, 2]})  # ax1 = heatmap, ax2 = colormap\n",
    "\n",
    "    twin1 = ax1.twiny()\n",
    "    \n",
    "    if is_11x34_data:\n",
    "        yticklabels=[\n",
    "            'Metadata',\n",
    "            'Dora indicators',\n",
    "            'Pov hand',\n",
    "            'P0 melds',\n",
    "            'P1 melds',\n",
    "            'P2 melds',\n",
    "            'P3 melds',\n",
    "            'P0 pool',\n",
    "            'P1 pool',\n",
    "            'P2 pool',\n",
    "            'P3 pool',\n",
    "        ]\n",
    "    else:\n",
    "        yticklabels=[\n",
    "            'Metadata',\n",
    "            'Dora indicators',\n",
    "            'Pov hand',\n",
    "            'P0 melds',\n",
    "            'P1 melds',\n",
    "            'P2 melds',\n",
    "            'P3 melds',\n",
    "            'P0 pool',\n",
    "            'P1 pool',\n",
    "            'P2 pool',\n",
    "            'P3 pool',\n",
    "            'P0 discards',\n",
    "            'P1 discards',\n",
    "            'P2 discards',\n",
    "            'P3 discards',\n",
    "        ]\n",
    "    \n",
    "    # TODO: Mask for interesting effects?\n",
    "#     mask = np.zeros((11, 34))\n",
    "#     mask[0, 5:10] = 1\n",
    "    \n",
    "    # Common Params\n",
    "    heatmap_params = dict(\n",
    "        ax=ax1,\n",
    "        annot=True,\n",
    "        fmt='g',\n",
    "#         mask=mask,\n",
    "        square=False,\n",
    "        xticklabels=ticks_tiles_oneline,\n",
    "        yticklabels=yticklabels,     \n",
    "        annot_kws={\"fontsize\": annot_fontsize},\n",
    "        robust=True,        \n",
    "        cbar=True,  # cbar param is always true, but we instead turn it invisible later if cbar is disabled\n",
    "        cbar_ax=ax2,\n",
    "        cbar_kws=dict(\n",
    "            shrink=0.3, \n",
    "            label='Category code',\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Extension of Params\n",
    "    if color_scheme == 'attention':\n",
    "        heatmap_params.update(dict(\n",
    "            cmap=\"icefire\",\n",
    "#             vmin=-10,\n",
    "#             vmax=10,\n",
    "        ))\n",
    "    elif color_scheme == 'plain':\n",
    "#         mask = np.zeros((11, 34))\n",
    "#         mask[0, 14:34] = 1\n",
    "        heatmap_params.update(dict(\n",
    "#             mask=mask,\n",
    "            norm=matplotlib.colors.BoundaryNorm([-128, 0, 1, 2, 3, 4, 128], 7),\n",
    "            cmap=sns.color_palette([\"#000000\",\n",
    "                                    \"#FFFFFF\", \n",
    "                                    \"#EA2027\", \n",
    "                                    \"#EE5A24\", \n",
    "                                    \"#F79F1F\", \n",
    "                                    \"#FFC312\", ])))\n",
    "    else:\n",
    "        heatmap_params.update(dict(cmap=sns.color_palette([\"#FFFFFF\"])))  # All white\n",
    "        \n",
    "\n",
    "        \n",
    "    if grid_color == None:\n",
    "        linewidths = 0\n",
    "    else:\n",
    "        heatmap_params.update(dict(linewidths=1, linecolor=grid_color))\n",
    "    \n",
    "    # Heatmap Creation\n",
    "    ax1 = sns.heatmap(pd.DataFrame(input_array), **heatmap_params)\n",
    "\n",
    "#     twin1.set_xlabel(\"Metadata Labels\")\n",
    "    twin1.set_xlim(ax1.get_xlim())\n",
    "    twin1.set_xticks(ax1.get_xticks())\n",
    "    metadata_labels = [\n",
    "        'Round wind',\n",
    "        'Dealer',\n",
    "        'POV player',\n",
    "        '# honba sticks',\n",
    "        '# riichi sticks',\n",
    "        '# wall tiles',\n",
    "        'P0 score',\n",
    "        'P1 score',\n",
    "        'P2 score',\n",
    "        'P3 score',\n",
    "        'P0 riichi status',\n",
    "        'P1 riichi status',\n",
    "        'P2 riichi status',\n",
    "        'P3 riichi status',\n",
    "    ] + ['Padding' for _ in range(20)]\n",
    "    twin1.set_xticklabels(labels=metadata_labels, rotation='vertical')\n",
    "    twin1.grid(False)  # Remove weird white vertical lines that sometimes appears\n",
    "\n",
    "    ax1.hlines(range(1, 2), -0.5, 34.5, linewidth=7, color=grid_color)  # Metadata separator line\n",
    "\n",
    "    # Ticks Configuration\n",
    "    ax1.tick_params(left=False, bottom=False, top=False, labelsize=tick_fontsize)\n",
    "    twin1.tick_params(top=False, labelsize=tick_fontsize)\n",
    "    plt.yticks(fontsize=tick_fontsize)\n",
    "    plt.xticks(fontsize=tick_fontsize)\n",
    "    \n",
    "    sns.despine(left=True, bottom=True)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    \n",
    "    if not cbar:\n",
    "        ax2.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Index Heatmap\n",
    "generate_input_heatmap(np.arange(0, 374).reshape(11, 34), cbar=False, color_scheme='white', title=None)\n",
    "generate_input_heatmap(np.arange(0, 374).reshape(11, 34), cbar=False, color_scheme='attention', title=None)\n",
    "\n",
    "\n",
    "# Validation Heatmaps\n",
    "model.eval()\n",
    "\n",
    "n_inputs = 5\n",
    "x = validation_dataset[100:105]['X'].to(DEVICE)  # GET CORRECT DATA\n",
    "x = x.reshape(1, x.shape[0], 374)\n",
    "attn_output, _ = model.mha1(query=x, key=x, value=x, need_weights=None)\n",
    "attn_output = attn_output.reshape(n_inputs, 374)\n",
    "\n",
    "for i, attention_values in enumerate(attn_output):\n",
    "    \n",
    "    pretty_print_x(x[0, i])\n",
    "\n",
    "    \n",
    "    x_arr = x[0, i].cpu().detach().numpy().reshape(11, 34)\n",
    "    generate_input_heatmap(x_arr, cbar=False, color_scheme='plain')\n",
    "\n",
    "    \n",
    "    attention_result = attention_values.reshape(11, 34).cpu().detach().numpy()\n",
    "    attention_result = np.around(attention_result, decimals=0)\n",
    "    generate_input_heatmap(attention_result, color_scheme='attention', grid_color=None)\n",
    "    generate_input_heatmap(attention_result, color_scheme='attention', grid_color='white')\n",
    "    generate_input_heatmap(attention_result, color_scheme='attention', grid_color='black')\n",
    "\n",
    "    break # TODO: REMOVE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretty Print Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "from IPython.display import SVG, HTML, Image\n",
    "\n",
    "import utilities.tiles as tc\n",
    "from utilities.shanten import Shanten\n",
    "\n",
    "import utilities.mahjong_drawer.mahjong_drawer.mahjong_drawer_module as drawer\n",
    "\n",
    "\n",
    "def get_mahjong_string(array: np.array):\n",
    "    return tc.TilesConverter.to_one_line_string(tc.TilesConverter.to_136_array(array.tolist())).replace('z', 'h')\n",
    "\n",
    "# Utility Classes\n",
    "md = drawer.MahjongDrawer('utilities/mahjong_drawer/mahjong_drawer/svg')\n",
    "shanten = Shanten()\n",
    "\n",
    "def get_tile_svg(class_number: int):\n",
    "    \"\"\" Faster fetch for single tile. \"\"\"\n",
    "    svg_folder = \"utilities/mahjong_drawer/mahjong_drawer/svg/\"\n",
    "    if class_number < 9:\n",
    "        return svg_folder + \"tile_m{}!.svg\".format(class_number + 1)\n",
    "    elif 9 <= class_number < 18:\n",
    "        return svg_folder + \"tile_p{}!.svg\".format(class_number - 9 + 1)\n",
    "    elif 18 <= class_number < 27:\n",
    "        return svg_folder + \"tile_s{}!.svg\".format(class_number - 18 + 1)\n",
    "    else:\n",
    "        return svg_folder + \"tile_h{}!.svg\".format(class_number - 27 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_winds_relative_to_dealer(dealer, pov):\n",
    "    \n",
    "    winds = [\n",
    "        ['EAST', 'SOUTH', 'WEST', 'NORTH'],\n",
    "        ['NORTH', 'EAST', 'SOUTH', 'WEST'],\n",
    "        ['WEST', 'NORTH', 'EAST', 'SOUTH'],\n",
    "        ['SOUTH', 'WEST', 'NORTH', 'EAST']\n",
    "    ]\n",
    "    \n",
    "    relative_to_dealer = winds[dealer]\n",
    "    \n",
    "    for _ in range(pov):\n",
    "        relative_to_dealer.append(relative_to_dealer.pop(0))\n",
    "    \n",
    "    return relative_to_dealer\n",
    "    \n",
    "def get_player_numbers(pov):\n",
    "    if pov == 0:\n",
    "        return [0, 1, 2, 3]\n",
    "    elif pov == 1:\n",
    "        return [1, 2, 3, 0]\n",
    "    elif pov == 2:\n",
    "        return [2, 3, 0, 1]\n",
    "    else:\n",
    "        return [3, 0, 1, 2]\n",
    "\n",
    "\n",
    "def picture_print_x(x, round_num, step_num, target=None, predicted=None, game_id=None):\n",
    "    \n",
    "    display(HTML(f\"\"\"\n",
    "        <h1>{'EAST' if x[0] == 0 else 'SOUTH'} {x[1]} - ROUND {round_num} - Step {step_num}</h1>\n",
    "    \"\"\"))\n",
    "    \n",
    "    if game_id:\n",
    "        print(f\"https://tenhou.net/5/?log={game_id}&tw={x[2]}&ts={round_num}&tj={step_num}\")\n",
    "#     print(f\"Honba-Riichi Count: {x[3]}/{x[4]}\")\n",
    "#     print(f\"Wall Tiles left: {x[5]}\")\n",
    "\n",
    "    # Meld / Discard creation\n",
    "    m_string = get_mahjong_string(x[34:68])  # Dora Indicators\n",
    "    n_backs = 5 - sum(c.isdigit() for c in m_string)\n",
    "    md.add_hand('b' + m_string + ('b' * n_backs), 'out/dora.svg')\n",
    "    for i in range(4):\n",
    "        md.create_discard_pile(get_mahjong_string(x[102 + (34 * i):136 + (34 * i)]), f'out/meld_{i}.svg')\n",
    "        md.create_discard_pile(get_mahjong_string(x[238 + (34 * i):272 + (34 * i)]), f'out/pool_{i}.svg')\n",
    "        \n",
    "    # POV Hand Management\n",
    "    pov_hand = x[68:102]\n",
    "    n_tiles = sum(pov_hand)\n",
    "    m_string_hand = get_mahjong_string(pov_hand).replace('z', 'h')\n",
    "    m_string_hand = m_string_hand + (' ' * (14 - n_tiles))  # TODO: ADD AFTER KERNEL RESET\n",
    "    md.add_hand(m_string_hand, 'out/hand.svg')\n",
    "    \n",
    "    target_shanten = 69\n",
    "    if target is not None:\n",
    "#         temp_34 = np.zeros(34, dtype=int)\n",
    "#         temp_34[target] = 1\n",
    "#         md.add_hand(get_mahjong_string(temp_34), f'out/target.svg')\n",
    "        \n",
    "        # shanten calculation\n",
    "        next_hand = pov_hand.tolist()\n",
    "        next_hand[target] -= 1\n",
    "        target_shanten = shanten.calculate_shanten(next_hand)\n",
    "\n",
    "\n",
    "    predicted_shantens = []\n",
    "    if predicted is not None:\n",
    "        for i, p in enumerate(predicted):\n",
    "#             temp_34 = np.zeros(34, dtype=int)\n",
    "#             temp_34[p] = 1\n",
    "#             md.add_hand(get_mahjong_string(temp_34), f'out/prediction_{i}.svg')\n",
    "#             sleep(0.25)\n",
    "            \n",
    "            # shanten calculation\n",
    "            next_hand = pov_hand.tolist()\n",
    "            next_hand[p] -= 1\n",
    "            predicted_shantens.append(shanten.calculate_shanten(next_hand))\n",
    "            \n",
    "    assert len(predicted_shantens) == len(predicted)\n",
    "    \n",
    "#     sleep(0.2)\n",
    "#     print(f\"HAND: {n_tiles} tiles - Efficiency Calculator: https://tenhou.net/2/?q={m_string_hand.replace('h', 'z')}\")\n",
    "#     display(Image(url='out/hand.svg', width=500))\n",
    "#     print(f\"Hand is {shanten.calculate_shanten(pov_hand.tolist())}-shanten\")  # Shanten for hand is pretty confusing!\n",
    "       \n",
    "    \n",
    "    relative_players = get_player_numbers(x[2])\n",
    "    relative_winds = get_winds_relative_to_dealer(x[1], x[2])\n",
    "    \n",
    "    # Player HTML\n",
    "    p0_b = f'<small style=\"color:blue\">P{relative_players[0]}</small>'\n",
    "    p1_b = f'<small style=\"color:blue\">P{relative_players[1]}</small>'\n",
    "    p2_b = f'<small style=\"color:blue\">P{relative_players[2]}</small>'\n",
    "    p3_b = f'<small style=\"color:blue\">P{relative_players[3]}</small>'\n",
    "    \n",
    "    p0 = f'<small>P{relative_players[0]}</small>'\n",
    "    p1 = f'<small>P{relative_players[1]}</small>'\n",
    "    p2 = f'<small>P{relative_players[2]}</small>'\n",
    "    p3 = f'<small>P{relative_players[3]}</small>'\n",
    "\n",
    "#     sleep(3.0)\n",
    "    display(HTML(f\"\"\"\n",
    "        <table>\n",
    "\n",
    "            <tr style=\"vertical-align:text-bottom\">\n",
    "                <th style=\"text-align:center\">  <h2                                          >{relative_winds[0]} </h2>  </h1>POV (You)            <br> {p0_b} </th>\n",
    "                <th style=\"text-align:center\">  <h2 style={\"color:red\" if x[11] == 1 else \"\"}>{relative_winds[1]} </h2>  </h1>Player to your Right <br> {p1_b} </th>\n",
    "                <th style=\"text-align:center\">  <h2 style={\"color:red\" if x[12] == 1 else \"\"}>{relative_winds[2]} </h2>  </h1>Player across you    <br> {p2_b} </th>\n",
    "                <th style=\"text-align:center\">  <h2 style={\"color:red\" if x[13] == 1 else \"\"}>{relative_winds[3]} </h2>  </h1>Player to your Left  <br> {p3_b} </th>\n",
    "                <th style=\"text-align:center\">  <br><br><br>Dora Indicators</th>\n",
    "\n",
    "            </tr> \n",
    "            <!--\n",
    "            <tr>\n",
    "                <th style=\"text-align:center\">P0 Score</th>\n",
    "                <th style=\"text-align:center\">P1 Score</th>\n",
    "                <th style=\"text-align:center\">P2 Score</th>\n",
    "                <th style=\"text-align:center\">P3 Score</th>\n",
    "            </tr> \n",
    "            -->\n",
    "            <tr>\n",
    "                <td style=\"text-align:center\">~{x[6] * 1000}pts</td>\n",
    "                <td style=\"text-align:center\">~{x[7] * 1000}pts</td>\n",
    "                <td style=\"text-align:center\">~{x[8] * 1000}pts</td>\n",
    "                <td style=\"text-align:center\">~{x[9] * 1000}pts</td>\n",
    "                <td><img src='out/dora.svg'   width=200></td>\n",
    "            </tr>\n",
    "            <!--tr>\n",
    "                <th style=\"text-align:center\"><h5>{p0} Pool</h5></th>\n",
    "                <th style=\"text-align:center\"><h5>{p1} Pool</h5></th>\n",
    "                <th style=\"text-align:center\"><h5>{p2} Pool</h5></th>\n",
    "                <th style=\"text-align:center\"><h5>{p3} Pool</h5></th>\n",
    "                <th style=\"text-align:center\">Dora Indicators</th>\n",
    "\n",
    "            </tr--> \n",
    "            <tr>\n",
    "                <th colspan=\"4\" style=\"text-align:center\"> <h4>Pools</h4> </th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td><img src='out/pool_0.svg' width=200></td>\n",
    "                <td><img src='out/pool_1.svg' width=200></td>\n",
    "                <td><img src='out/pool_2.svg' width=200></td>\n",
    "                <td><img src='out/pool_3.svg' width=200></td>\n",
    "                <td>Wall Tiles left:<h1>{x[5]}</h1></td>\n",
    "            </tr>\n",
    "            <!--tr>\n",
    "                <th style=\"text-align:center\">{p0} Melds</th>\n",
    "                <th style=\"text-align:center\">{p1} Melds</th>\n",
    "                <th style=\"text-align:center\">{p2} Melds</th>\n",
    "                <th style=\"text-align:center\">{p3} Melds</th>\n",
    "            </tr--> \n",
    "            <tr>\n",
    "                <th colspan=\"4\" style=\"text-align:center\"> <h4>Melds</h4> </th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td><img src='out/meld_0.svg' width=200></td>\n",
    "                <td><img src='out/meld_1.svg' width=200></td>\n",
    "                <td><img src='out/meld_2.svg' width=200></td>\n",
    "                <td><img src='out/meld_3.svg' width=200></td>\n",
    "                <td>Honba/Riichi Count:<h1>{x[3]}/{x[4]}</h1></td>\n",
    "            </tr>\n",
    "            \n",
    "            <!--tr>\n",
    "                <th colspan=\"4\" style=\"text-align:center\"> <h4>POV Hand</h4> </th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td colspan=\"4\">\n",
    "                    <figure style=\"text-align:center\">\n",
    "                        <img src=\"out/hand.svg\" width=500>\n",
    "                        <figcaption style=\"text-align:center\">POOOOOP</figcaption>\n",
    "                    </figure>\n",
    "                </td>\n",
    "            </tr-->\n",
    "        </table>\n",
    "    \"\"\"))\n",
    "    \n",
    "    print(f\"HAND: {n_tiles} tiles - Efficiency Calculator: https://tenhou.net/2/?q={m_string_hand.replace('h', 'z')}\")\n",
    "    display(Image(url='out/hand.svg', width=500))\n",
    "#     print(f\"Hand is {shanten.calculate_shanten(pov_hand.tolist())}-shanten\")  # Shanten for hand is pretty confusing!\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "#     sleep(0.3)\n",
    "    if predicted is not None and target is not None:\n",
    "        display(HTML(\"\"\"\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <th style=\"text-align:center\"><h3>Target</h3></th>\n",
    "                    <th style=\"text-align:center\"><h3>1st Prediction</h3></th>\n",
    "                    <th style=\"text-align:center\"><h3>2nd Prediction</h3></th>\n",
    "                    <th style=\"text-align:center\"><h3>3rd Prediction</h3></th>\n",
    "\n",
    "                </tr> \n",
    "                \n",
    "                <tr>\n",
    "                    <td>\n",
    "                        <figure style=\"text-align:center\">\n",
    "                            <img src={}    width=60>\n",
    "                            <figcaption style=\"text-align:center\">{}<br>Class {}<h5>{}-shanten</h5></figcaption>\n",
    "                        </figure>\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        <figure style=\"text-align:center\">\n",
    "                            <img src={} width=60>\n",
    "                            <figcaption style=\"text-align:center\">{}<br>Class {}<h5>{}-shanten</h5></figcaption>\n",
    "                        </figure>\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        <figure style=\"text-align:center\">\n",
    "                            <img src={} width=60>\n",
    "                            <figcaption style=\"text-align:center\">{}<br>Class {}<h5>{}-shanten</h5></figcaption>\n",
    "                        </figure>\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        <figure style=\"text-align:center\">\n",
    "                            <img src={} width=60>\n",
    "                            <figcaption style=\"text-align:center\">{}<br>Class {}<h5>{}-shanten</h5></figcaption>\n",
    "                        </figure>\n",
    "                    </td>\n",
    "                </tr>\n",
    "                \n",
    "                <!--tr>\n",
    "                    <td>\n",
    "                        <h3 style=\"text-align:center\">-shanten</h3>\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        <h3 style=\"text-align:center\">-shanten</h3>\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        <h3 style=\"text-align:center\">-shanten</h3>\n",
    "                    </td>\n",
    "                    <td>\n",
    "                        <h3 style=\"text-align:center\">-shanten</h3>\n",
    "                    </td>\n",
    "\n",
    "                </tr-->\n",
    "                \n",
    "            </table>\n",
    "        \"\"\".format(get_tile_svg(target), ticks_tiles_oneline[target], target, target_shanten,\n",
    "                   get_tile_svg(predicted[0]), ticks_tiles_oneline[predicted[0]], predicted[0],predicted_shantens[0],\n",
    "                   get_tile_svg(predicted[1]), ticks_tiles_oneline[predicted[1]], predicted[1],predicted_shantens[1],\n",
    "                   get_tile_svg(predicted[2]), ticks_tiles_oneline[predicted[2]], predicted[2],predicted_shantens[2],\n",
    "#                    target_shanten, \n",
    "#                    predicted_shantens[0], \n",
    "#                    predicted_shantens[1], \n",
    "#                    predicted_shantens[2]\n",
    "                  ))\n",
    "               )\n",
    "    \n",
    "#     print(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporary Load Dataset\n",
    "\n",
    "Both kans happens in the same round (Round 4):\n",
    "https://tenhou.net/4/?log=2019010100gm-00a9-0000-9a5b695e&tw=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLOADING DATASETS:\\n\")\n",
    "\n",
    "# Setup of Parameters\n",
    "ds_path = Path.home() / 'MasterThesis' / 'data' / 'discard_datasets_new'\n",
    "# ds_path = Path(\"picked_logs\")  # Get path\n",
    "\n",
    "# Training Dataset\n",
    "temp_dataset = DiscardDataset(ds_path,\n",
    "                              years=[2018],\n",
    "                              balance_data=False,\n",
    "                              n_rows=1000,\n",
    "                              discard_type=DiscardDataset.DiscardType.POOL\n",
    "                             )\n",
    "\n",
    "print(f\"DATASET TYPE: {temp_dataset.discard_type}\")\n",
    "\n",
    "temp_loader = torch.utils.data.DataLoader(temp_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# TODO: SWITCH DATA LOADER TO TEST LOADER!\n",
    "for batch_idx, batch in enumerate(tqdm(temp_loader, total=len(temp_loader), desc=f'Testing', unit='batch')):\n",
    "    \n",
    "#     if batch_idx == 10:\n",
    "#         break\n",
    "        \n",
    "    game_id = batch['game_id'][0]\n",
    "    round_num = batch['round'][0]\n",
    "    step_num = batch['step'][0]\n",
    "    X = batch['X'].to(DEVICE)\n",
    "    y = batch['y'].to(DEVICE)\n",
    "    \n",
    "#     # TODO: REMOVE FILTER\n",
    "#     if X[0][0] != 0:  # Wind\n",
    "#         continue\n",
    "#     if X[0][1] != 2:  # Dealer\n",
    "#         continue\n",
    "    \n",
    "    if torch.sum(X[0][102:238]) == 0:\n",
    "        continue\n",
    "\n",
    "    if X[0][5] >= 30:  # Tiles Left\n",
    "        continue\n",
    "\n",
    "#     if batch['round'] != 9:  # ROUND NUMBER # TODO: THIS WILL BE REMOVED IN LATER ITERATION\n",
    "#         continue\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        output = model(X)\n",
    "    \n",
    "    logits = output[0]  # output is shape[1, 34] due to batching process, this line undoes it to shape[34]\n",
    "    prediction = torch.softmax(logits, dim=0)\n",
    "    \n",
    "    x_formatted = X.cpu().numpy().astype(int).reshape(-1)\n",
    "    y_formatted = y.cpu().numpy().astype(int).reshape(-1)[0]\n",
    "    \n",
    "    predictions = torch.argsort(prediction, descending=True).cpu().numpy().astype(int).reshape(-1)[0:3]\n",
    "    \n",
    "    sleep(1.0)  # Necessary to avoid wrong image save/load\n",
    "    picture_print_x(x_formatted, round_num=round_num, step_num=step_num, target=y_formatted, predicted=predictions, game_id=game_id)\n",
    "    \n",
    "    # Beautiful 2D print (Very Taxing!)\n",
    "#     generate_input_heatmap(x_formatted.reshape((11, 34)), cbar=False, color_scheme='plain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
