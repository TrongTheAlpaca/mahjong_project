{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import trange, tqdm\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from timeit import default_timer as timer\n",
    "\n",
    "import utilities.utilities as util\n",
    "\n",
    "# from pyarrow import parquet\n",
    "\n",
    "from typing import List\n",
    "from utilities.tiles import TilesConverter as tc\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_string(number, digits=136):\n",
    "    return \"{n:0>{d}b}\".format(n=number, d=digits)\n",
    "\n",
    "\n",
    "def int_to_136_binary(number: int) -> List[int]:\n",
    "    return [0 if number & 1 << 135 - i == 0 else 1 for i in range(136)]\n",
    "\n",
    "\n",
    "def int_to_136_array(number: int) -> List[int]:\n",
    "    \"\"\" Parses an int into an 136 tiles array. \"\"\"\n",
    "    return [i for i in range(136) if number & ((1 << 135) >> i) > 0]\n",
    "\n",
    "\n",
    "def int_to_34_indices(number: int) -> List[int]:\n",
    "    array = []\n",
    "    for i in range(34):\n",
    "        for j in range(4):\n",
    "            if number >> 135 - j - 4 * i & 1:  # Check if current bit equals 1\n",
    "                array.append(i)\n",
    "    return array\n",
    "\n",
    "\n",
    "def int_to_34_array(number: int) -> List[int]:\n",
    "    \"\"\" Parses an int into an 34 tiles array. \"\"\"\n",
    "    array = [0] * 34\n",
    "    for i in range(34):  # Iterate through bits from left-to-right\n",
    "        for j in range(4):  # 4 iteration per tile\n",
    "            if number >> 135 - j - 4 * i & 1:  # Check if current bit equals 1\n",
    "                array[i] += 1\n",
    "    return array\n",
    "\n",
    "\n",
    "def column_to_34_nparray(numbers: np.array) -> np.array:\n",
    "    \"\"\" N x 1 Binary Array is expanded to N x 34 Int matrix \"\"\"\n",
    "\n",
    "    # Hot bit counts for 4 bits\n",
    "    bit_lookup = {\n",
    "        0b0000: 0,\n",
    "        0b0001: 1,\n",
    "        0b0010: 1,\n",
    "        0b0011: 2,\n",
    "        0b0100: 1,\n",
    "        0b0101: 2,\n",
    "        0b0110: 2,\n",
    "        0b0111: 3,\n",
    "        0b1000: 1,\n",
    "        0b1001: 2,\n",
    "        0b1010: 2,\n",
    "        0b1011: 3,\n",
    "        0b1100: 2,\n",
    "        0b1101: 3,\n",
    "        0b1110: 3,\n",
    "        0b1111: 4\n",
    "    }\n",
    "\n",
    "    array = np.zeros((len(numbers), 34), dtype=np.int8)\n",
    "    for row, v in enumerate(tqdm(numbers, position=0, disable=DISABLE_TQDM)):\n",
    "        for i in range(34):\n",
    "            array[row, 33 - i] = bit_lookup[(v >> (4 * i)) & 0b1111]  # Right-to-Left Masking\n",
    "    return array\n",
    "\n",
    "\n",
    "def int_to_mahjong_string(number):\n",
    "    \"\"\"\n",
    "    Convert integer to the one line mahjong string (akadora=0)\n",
    "    Example of output:  1244079m3p57z\n",
    "    \"\"\"\n",
    "    return tc.to_one_line_string(int_to_136_array(number), print_aka_dora=True)\n",
    "\n",
    "\n",
    "def generate_hand_state_column(df, player):\n",
    "    mask = (df.player.values == player) & (df.action.values.isin(['Ron', 'Draw', 'Discard', 'Riichi']))\n",
    "    call_mask = (df.player.values == player) & (\n",
    "        df.action.values.isin(['Chi', 'Pon', 'MinKan', 'AnKan', 'KaKan', 'Nuki']))\n",
    "\n",
    "    hand = df.tile.to_numpy(dtype='object')\n",
    "    call = df.tile.to_numpy(dtype='object')\n",
    "\n",
    "    hand[mask] = 1 << (135 - hand[mask])\n",
    "    hand[~mask] = 0\n",
    "\n",
    "    call[call_mask] = 1 << (135 - call[call_mask])\n",
    "    call[~call_mask] = 0\n",
    "\n",
    "    init_indices = df.index[df['action'] == 'Init'].tolist()\n",
    "    hands = np.array_split(hand, init_indices)[1:]\n",
    "    calls = np.array_split(call, init_indices)[1:]\n",
    "\n",
    "    rounds = []\n",
    "    for i in trange(len(hands), desc=f\"p{player}_hand\", disable=DISABLE_TQDM):\n",
    "        hands[i] = np.bitwise_xor.accumulate(hands[i])\n",
    "        calls[i] = np.bitwise_or.accumulate(calls[i])\n",
    "\n",
    "        rounds.append(hands[i] & ~calls[i])\n",
    "\n",
    "    return np.concatenate(rounds)\n",
    "\n",
    "\n",
    "def generate_meld_state_column(df, player):\n",
    "    call_mask = (df.player.values == player) & (\n",
    "        df.action.values.isin(['Chi', 'Pon', 'MinKan', 'AnKan', 'KaKan', 'Nuki']))\n",
    "    remove_mask = (df.player.values == player) & (df.action == 'Remove')\n",
    "\n",
    "    call = df.tile.to_numpy(dtype='object')\n",
    "    kill = df.tile.to_numpy(dtype='object')\n",
    "\n",
    "    call[call_mask] = 1 << (135 - call[call_mask])\n",
    "    call[~call_mask] = 0\n",
    "\n",
    "    kill[remove_mask] = 1 << (135 - kill[remove_mask])\n",
    "    kill[~remove_mask] = 0\n",
    "\n",
    "    init_indices = df.index[df['action'] == 'Init'].tolist()\n",
    "    calls = np.array_split(call, init_indices)[1:]\n",
    "    kills = np.array_split(kill, init_indices)[1:]\n",
    "\n",
    "    rounds = []\n",
    "    for i in trange(len(calls), desc=f\"p{player}_meld\", disable=DISABLE_TQDM):\n",
    "        kills[i] = np.bitwise_or.accumulate(kills[i])\n",
    "        calls[i] = np.bitwise_or.accumulate(calls[i])\n",
    "\n",
    "        rounds.append(calls[i] & ~kills[i])\n",
    "\n",
    "    return np.concatenate(rounds)\n",
    "\n",
    "\n",
    "def generate_discard_state_column(df, player):\n",
    "    discard_mask = (df.player.values == player) & ((df.action == 'Discard') | (df.action == 'Riichi'))\n",
    "\n",
    "    discard = df.tile.to_numpy(dtype='object')\n",
    "\n",
    "    discard[discard_mask] = 1 << (135 - discard[discard_mask])\n",
    "    discard[~discard_mask] = 0\n",
    "\n",
    "    init_indices = df.index[df['action'] == 'Init'].tolist()\n",
    "    discards = np.array_split(discard, init_indices)[1:]\n",
    "\n",
    "    rounds = []\n",
    "    for i in trange(len(discards), desc=f\"p{player}_disc\", disable=DISABLE_TQDM):\n",
    "        discards[i] = np.bitwise_or.accumulate(discards[i])\n",
    "\n",
    "        rounds.append(discards[i])\n",
    "\n",
    "    return np.concatenate(rounds)\n",
    "\n",
    "\n",
    "def generate_pool_state_column(df, player):\n",
    "    discard_mask = (df.player.values == player) & ((df.action == 'Discard') | (df.action == 'Riichi'))\n",
    "    steal_mask = (df.player.values == player) & (df.action.values.isin(['Remove', 'Chi', 'Pon', 'MinKan']))\n",
    "\n",
    "    pool = df.tile.to_numpy(dtype='object')\n",
    "    steal = df.tile.to_numpy(dtype='object')\n",
    "\n",
    "    pool[discard_mask] = 1 << (135 - pool[discard_mask])\n",
    "    pool[~discard_mask] = 0\n",
    "\n",
    "    steal[steal_mask] = 1 << (135 - steal[steal_mask])\n",
    "    steal[~steal_mask] = 0\n",
    "\n",
    "    init_indices = df.index[df['action'] == 'Init'].tolist()\n",
    "    pools = np.array_split(pool, init_indices)[1:]\n",
    "    steals = np.array_split(steal, init_indices)[1:]\n",
    "\n",
    "    rounds = []\n",
    "    for i in trange(len(pools), desc=f\"p{player}_pool\", disable=DISABLE_TQDM):\n",
    "        pools[i] = np.bitwise_or.accumulate(pools[i])\n",
    "        steals[i] = np.bitwise_or.accumulate(steals[i])\n",
    "\n",
    "        rounds.append(pools[i] & ~steals[i])\n",
    "\n",
    "    return np.concatenate(rounds)\n",
    "\n",
    "\n",
    "def generate_dora_state_column(df):\n",
    "    mask = (df.action == 'Dora')\n",
    "\n",
    "    dora = df.tile.to_numpy(dtype='object')\n",
    "\n",
    "    dora[mask] = 1 << (135 - dora[mask])\n",
    "    dora[~mask] = 0\n",
    "\n",
    "    init_indices = df.index[df['action'] == 'Init'].tolist()\n",
    "    doras = np.array_split(dora, init_indices)[1:]\n",
    "\n",
    "    return np.concatenate(\n",
    "        [np.bitwise_or.accumulate(doras[i]) for i in trange(len(doras), desc=f\"dora\", disable=DISABLE_TQDM)])\n",
    "\n",
    "\n",
    "def generate_wall_state_column(df):\n",
    "    wall = np.zeros(len(df), dtype=int)\n",
    "    wall[df.action == 'Init'] = 122\n",
    "    wall[df.action == 'Draw'] = 1\n",
    "\n",
    "    init_indices = df.index[df['action'] == 'Init'].tolist()\n",
    "    walls = np.array_split(wall, init_indices)[1:]\n",
    "\n",
    "    return np.concatenate(\n",
    "        [np.subtract.accumulate(walls[i]) for i in trange(len(walls), desc=f\"wall\", disable=DISABLE_TQDM)])\n",
    "\n",
    "\n",
    "def generate_riichi_state_column(df, player):\n",
    "    result = np.zeros(len(df), dtype=np.bool)\n",
    "\n",
    "    riichi_indices = df.index[(df.player == player) & (df.action == 'Riichi')].tolist()\n",
    "    end_indices = df.index[df.action.isin(['Ron', 'Tsumo', 'Ryuukyoku'])].tolist()\n",
    "\n",
    "    end = -1\n",
    "    for start in riichi_indices:\n",
    "        while end < start:\n",
    "            end = end_indices.pop(0)\n",
    "\n",
    "        # TODO: `start` instead of +1? If we want to include riichi declarations in discard dataset\n",
    "        result[start + 1:end + 1] = True\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_phase_column(df: pd.DataFrame) -> np.array:\n",
    "    # Begin with merging all pools together\n",
    "    phase = df[f'p0_pool'].to_numpy(dtype='object') | \\\n",
    "            df[f'p1_pool'].to_numpy(dtype='object') | \\\n",
    "            df[f'p2_pool'].to_numpy(dtype='object') | \\\n",
    "            df[f'p3_pool'].to_numpy(dtype='object')\n",
    "\n",
    "    # Translate merged pool into phases\n",
    "    for i, x in enumerate(phase):\n",
    "        ones = bin(int(x)).count(\"1\")\n",
    "        if ones <= 24:\n",
    "            phase[i] = 0  # Early Game\n",
    "        elif 24 < ones <= 48:\n",
    "            phase[i] = 1  # Mid Game\n",
    "        else:\n",
    "            phase[i] = 2  # End Game\n",
    "\n",
    "    return phase\n",
    "\n",
    "\n",
    "def undo_bit(df, player_id, source):\n",
    "    \"\"\" Performant bit flipping via XOR. \"\"\"\n",
    "    tile_binary = 1 << (135 - df.tile.to_numpy(dtype='object'))  # Transforms tile values to one-hot-encodings\n",
    "    return np.where(df['player'].to_numpy() == player_id,  # Undo for discarding player\n",
    "                    df[f'p{player_id}_{source}'].to_numpy(dtype='object') ^ tile_binary,  # Perform XOR if True\n",
    "                    df[f'p{player_id}_{source}'].to_numpy(dtype='object'))  # Do nothing if False\n",
    "\n",
    "\n",
    "def roll_columns(arr: np.array, player_column_index: int, target: int):\n",
    "    \"\"\"\n",
    "    Roll columns to emulate relativeness of player seats compared to player POV.\n",
    "    NB: This is operation modifies the given array inplace!\n",
    "\n",
    "    player_column_index: the column index for the player column.\n",
    "    target: the start index of the 4 columns to be rolled. E.g. target = 5, then column 5,6,7,8 will be rolled.\n",
    "    \"\"\"\n",
    "\n",
    "    # We skip rolling player 0's rows as they are already in correct format\n",
    "    for player in range(1, 4):\n",
    "        arr[:, target:target + 4][arr[:, player_column_index] == player] = np.roll(\n",
    "            arr[arr[:, player_column_index] == player][:, target:target + 4], shift=-player, axis=1)\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\" Divide iterable l into n-sized batches. \"\"\"\n",
    "    n = max(1, n)\n",
    "    return (l[i:i + n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISABLE_TQDM = True\n",
    "# CHUNK_SIZE = 1028\n",
    "INPUT_PATH =  Path.home() / 'MasterThesis' / 'data' / 'state_data_new'\n",
    "OUTPUT_PATH = Path.home() / 'MasterThesis' / 'data' / 'discard_datasets_new'\n",
    "\n",
    "YEARS = [\n",
    "    2009,\n",
    "]\n",
    "\n",
    "CURRENT_FILE_INDEX = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Round Data\n",
    "Load this once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>round_wind</th>\n",
       "      <th>dealer</th>\n",
       "      <th>winner</th>\n",
       "      <th>honba</th>\n",
       "      <th>riichibo</th>\n",
       "      <th>p0_start_score</th>\n",
       "      <th>p1_start_score</th>\n",
       "      <th>p2_start_score</th>\n",
       "      <th>p3_start_score</th>\n",
       "      <th>p0_end_score</th>\n",
       "      <th>p1_end_score</th>\n",
       "      <th>p2_end_score</th>\n",
       "      <th>p3_end_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_id</th>\n",
       "      <th>round</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2009020103gm-00a9-0000-2453a04c</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2019123123gm-00e1-0000-f7f33877</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>25000</td>\n",
       "      <td>24000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21100</td>\n",
       "      <td>23000</td>\n",
       "      <td>23000</td>\n",
       "      <td>32900</td>\n",
       "      <td>21100</td>\n",
       "      <td>22000</td>\n",
       "      <td>23000</td>\n",
       "      <td>32900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13100</td>\n",
       "      <td>47000</td>\n",
       "      <td>15000</td>\n",
       "      <td>24900</td>\n",
       "      <td>13100</td>\n",
       "      <td>47000</td>\n",
       "      <td>14000</td>\n",
       "      <td>24900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16400</td>\n",
       "      <td>45900</td>\n",
       "      <td>13400</td>\n",
       "      <td>24300</td>\n",
       "      <td>16400</td>\n",
       "      <td>45900</td>\n",
       "      <td>13400</td>\n",
       "      <td>24300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16400</td>\n",
       "      <td>45900</td>\n",
       "      <td>12100</td>\n",
       "      <td>25600</td>\n",
       "      <td>16400</td>\n",
       "      <td>45900</td>\n",
       "      <td>12100</td>\n",
       "      <td>25600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23112760 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      round_wind dealer winner  honba  \\\n",
       "log_id                          round                                   \n",
       "2009020103gm-00a9-0000-2453a04c 0              0      0     -1      0   \n",
       "                                1              0      1     -1      1   \n",
       "                                2              0      2     -1      2   \n",
       "                                3              0      3     -1      3   \n",
       "                                4              1      0     -1      4   \n",
       "...                                          ...    ...    ...    ...   \n",
       "2019123123gm-00e1-0000-f7f33877 0              0      0      3      0   \n",
       "                                1              0      1      1      0   \n",
       "                                2              0      1      0      1   \n",
       "                                3              0      2      3      0   \n",
       "                                4              0      3      0      0   \n",
       "\n",
       "                                       riichibo  p0_start_score  \\\n",
       "log_id                          round                             \n",
       "2009020103gm-00a9-0000-2453a04c 0             0           25000   \n",
       "                                1             0           25000   \n",
       "                                2             0           25000   \n",
       "                                3             0           25000   \n",
       "                                4             0           25000   \n",
       "...                                         ...             ...   \n",
       "2019123123gm-00e1-0000-f7f33877 0             0           25000   \n",
       "                                1             0           21100   \n",
       "                                2             0           13100   \n",
       "                                3             0           16400   \n",
       "                                4             0           16400   \n",
       "\n",
       "                                       p1_start_score  p2_start_score  \\\n",
       "log_id                          round                                   \n",
       "2009020103gm-00a9-0000-2453a04c 0               25000           25000   \n",
       "                                1               25000           25000   \n",
       "                                2               25000           25000   \n",
       "                                3               25000           25000   \n",
       "                                4               25000           25000   \n",
       "...                                               ...             ...   \n",
       "2019123123gm-00e1-0000-f7f33877 0               25000           25000   \n",
       "                                1               23000           23000   \n",
       "                                2               47000           15000   \n",
       "                                3               45900           13400   \n",
       "                                4               45900           12100   \n",
       "\n",
       "                                       p3_start_score  p0_end_score  \\\n",
       "log_id                          round                                 \n",
       "2009020103gm-00a9-0000-2453a04c 0               25000         25000   \n",
       "                                1               25000         25000   \n",
       "                                2               25000         25000   \n",
       "                                3               25000         25000   \n",
       "                                4               25000         25000   \n",
       "...                                               ...           ...   \n",
       "2019123123gm-00e1-0000-f7f33877 0               25000         25000   \n",
       "                                1               32900         21100   \n",
       "                                2               24900         13100   \n",
       "                                3               24300         16400   \n",
       "                                4               25600         16400   \n",
       "\n",
       "                                       p1_end_score  p2_end_score  \\\n",
       "log_id                          round                               \n",
       "2009020103gm-00a9-0000-2453a04c 0             25000         25000   \n",
       "                                1             25000         25000   \n",
       "                                2             25000         25000   \n",
       "                                3             25000         25000   \n",
       "                                4             25000         25000   \n",
       "...                                             ...           ...   \n",
       "2019123123gm-00e1-0000-f7f33877 0             25000         25000   \n",
       "                                1             22000         23000   \n",
       "                                2             47000         14000   \n",
       "                                3             45900         13400   \n",
       "                                4             45900         12100   \n",
       "\n",
       "                                       p3_end_score  \n",
       "log_id                          round                \n",
       "2009020103gm-00a9-0000-2453a04c 0             25000  \n",
       "                                1             25000  \n",
       "                                2             25000  \n",
       "                                3             25000  \n",
       "                                4             25000  \n",
       "...                                             ...  \n",
       "2019123123gm-00e1-0000-f7f33877 0             24000  \n",
       "                                1             32900  \n",
       "                                2             24900  \n",
       "                                3             24300  \n",
       "                                4             25600  \n",
       "\n",
       "[23112760 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round_data = pd.read_parquet('log_round_meta.parquet', engine='fastparquet')  # about 450MB file\n",
    "round_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112217ea7d5842729b9b2dbcc48b8c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2015:   0%|          | 0/152280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d9763931e84dea9576ecdbbfeb4f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2019:   0%|          | 0/171629 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for year in YEARS:\n",
    "\n",
    "    (Path(OUTPUT_PATH) / str(year)).mkdir(exist_ok=True, parents=True)  # Create current year's folder\n",
    "\n",
    "    all_logs = [l for l in (INPUT_PATH / str(year)).iterdir()]\n",
    "    # chunked = chunks(all_logs, CHUNK_SIZE)\n",
    "\n",
    "#     print(year)\n",
    "    time.sleep(0.2)\n",
    "    # chunk_bar = tqdm(chunked, total=len(all_logs) // CHUNK_SIZE, unit=f\"batch({CHUNK_SIZE}) \", desc=f\"{year}\", position=0)\n",
    "    # chunk_bar = tqdm(all_logs, total=len(all_logs), unit=f\"batch({CHUNK_SIZE}) \", desc=f\"{year}\", position=0)\n",
    "    chunk_bar = tqdm(all_logs, total=len(all_logs), desc=f\"{year}\", position=0)\n",
    "    \n",
    "    for chunk in chunk_bar:\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Loading DataFrames into Memory]\"))\n",
    "\n",
    "        # print(\"[Loading DataFrames into Memory]\")\n",
    "\n",
    "        # dfs = parquet.ParquetDataset(chunk, use_legacy_dataset=False).read_pandas().to_pandas()\n",
    "        dfs = pd.read_parquet(chunk)\n",
    "\n",
    "        dfs.action = dfs.action.astype('category', copy=False)\n",
    "        # dfs = dfs.astype({\n",
    "        #     'log_id': pd.StringDtype(),\n",
    "        #     'round': 'uint8',\n",
    "        #     'step': 'uint8',\n",
    "        #     'player': 'int8',\n",
    "        #     'action': 'category',  # Category must be reassigned due to how parquet works\n",
    "        #     'tile': 'uint8'\n",
    "        # }, copy=False)\n",
    "\n",
    "        # Get Round Data\n",
    "        # Use `fastparquet` to preserve categorical data\n",
    "        # temp_round_data = round_data.copy()[round_data.index.isin(dfs['log_id'], level=0)]\n",
    "        temp_round_data = round_data.loc[chunk.stem]\n",
    "\n",
    "        # # Generate State DataFrame\n",
    "        # ```\n",
    "        # - DRAW    = 'Draw'\n",
    "        # - DISCARD = 'Discard'\n",
    "        # - CHI     = 'Chi'\n",
    "        # - PON     = 'Pon'\n",
    "        # - MINKAN  = 'MinKan'  # Open Kan\n",
    "        # - ANKAN   = 'AnKan'    # Closed Kan\n",
    "        # - KAKAN   = 'KaKan'    # Added Kan, also called 'Shouminkan'\n",
    "        # - NUKI    = 'Nuki'      # Declare North dora\n",
    "        # - REMOVE  = 'Remove'\n",
    "        # - REACH   = 'Riichi'\n",
    "        # ```\n",
    "\n",
    "        # This is where God has abandoned us.\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Generating States]\"))\n",
    "\n",
    "        dfs['p0_hand'] = generate_hand_state_column(dfs, 0)\n",
    "        dfs['p1_hand'] = generate_hand_state_column(dfs, 1)\n",
    "        dfs['p2_hand'] = generate_hand_state_column(dfs, 2)\n",
    "        dfs['p3_hand'] = generate_hand_state_column(dfs, 3)\n",
    "\n",
    "        dfs['p0_meld'] = generate_meld_state_column(dfs, 0)\n",
    "        dfs['p1_meld'] = generate_meld_state_column(dfs, 1)\n",
    "        dfs['p2_meld'] = generate_meld_state_column(dfs, 2)\n",
    "        dfs['p3_meld'] = generate_meld_state_column(dfs, 3)\n",
    "\n",
    "        dfs['p0_discard'] = generate_discard_state_column(dfs, 0)\n",
    "        dfs['p1_discard'] = generate_discard_state_column(dfs, 1)\n",
    "        dfs['p2_discard'] = generate_discard_state_column(dfs, 2)\n",
    "        dfs['p3_discard'] = generate_discard_state_column(dfs, 3)\n",
    "\n",
    "        dfs['p0_pool'] = generate_pool_state_column(dfs, 0)\n",
    "        dfs['p1_pool'] = generate_pool_state_column(dfs, 1)\n",
    "        dfs['p2_pool'] = generate_pool_state_column(dfs, 2)\n",
    "        dfs['p3_pool'] = generate_pool_state_column(dfs, 3)\n",
    "        #\n",
    "        # dfs['phase'] = generate_phase_column(dfs)\n",
    "\n",
    "        dfs['p0_riichi'] = generate_riichi_state_column(dfs, 0)\n",
    "        dfs['p1_riichi'] = generate_riichi_state_column(dfs, 1)\n",
    "        dfs['p2_riichi'] = generate_riichi_state_column(dfs, 2)\n",
    "        dfs['p3_riichi'] = generate_riichi_state_column(dfs, 3)\n",
    "\n",
    "        dfs['dora'] = generate_dora_state_column(dfs)\n",
    "\n",
    "        dfs['wall'] = generate_wall_state_column(dfs)\n",
    "\n",
    "        # CREATING THE DISCARD DATASET\n",
    "        # ----------------------------\n",
    "        # When the execution of code arrives here, the original DataFrame should be populated with board states.\n",
    "        # The following steps will alter said states to befit the DISCARD DATASET, which may be wrong in other cases.\n",
    "        # We will merge the ROUND DATAFRAME together with the DISCARD STATES to construct he final DISCARD DATASET.\n",
    "        dfs = dfs[(dfs.action == 'Discard') | (dfs.action == 'Riichi')]  # Focus only on the discard/riichi actions\n",
    "\n",
    "        # Remove cases where the discarding player is in Riichi\n",
    "        dfs = dfs[((dfs.player == 0) & (~dfs[f'p0_riichi'])) |\n",
    "                  ((dfs.player == 1) & (~dfs[f'p1_riichi'])) |\n",
    "                  ((dfs.player == 2) & (~dfs[f'p2_riichi'])) |\n",
    "                  ((dfs.player == 3) & (~dfs[f'p3_riichi']))]\n",
    "\n",
    "#         dfs = dfs.drop(columns=['step', 'action'])  # We won't be needing these columns anymore  # OLD VERSION FROM 2021-04-27\n",
    "        dfs = dfs.drop(columns=['action'])  # We won't be needing these columns anymore\n",
    "\n",
    "        dfs = dfs.set_index(['log_id', 'round']).join(temp_round_data, how='left')\n",
    "        dfs = dfs.reset_index()  # Need `round` value for later step\n",
    "\n",
    "        indices = list(dfs.columns)  # Get Column Indices before turning DF to np.array, useful for later steps\n",
    "\n",
    "        # STEP - UNDOING DISCARDING ACTIONS\n",
    "        # ---------------------------------\n",
    "        # We filter the logs for states where a player performs a discard action.\n",
    "        # If we undo the board state to the state before the discard has concluded,\n",
    "        # we get the state the discarding player had access to before determining which tile to discard.\n",
    "        #\n",
    "        # Undoing a discarding tile includes:\n",
    "        # - Adding the discarded tile back to hand\n",
    "        # - Remove the discarded tile from discarding player's pool\n",
    "        # - Remove the discarded tile from discarding player's discarding history\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Undoing Discards]\"))\n",
    "\n",
    "        # Undo for all four players\n",
    "        for row_index in trange(4, disable=DISABLE_TQDM):\n",
    "            dfs[f'p{row_index}_hand'] = undo_bit(dfs, row_index, 'hand')\n",
    "            dfs[f'p{row_index}_pool'] = undo_bit(dfs, row_index, 'pool')  # Comment this if you don't want pool in final data\n",
    "            dfs[f'p{row_index}_discard'] = undo_bit(dfs, row_index, 'discard')\n",
    "\n",
    "        # STEP - NORMALIZE PLAYER SCORES\n",
    "        # ------------------------------\n",
    "        # Effectively making them fit inside np.int8\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Normalize Scores]\"))\n",
    "\n",
    "        score_columns = [f'p{i}_start_score' for i in range(4)] + [f'p{i}_end_score' for i in range(4)]\n",
    "        dfs[score_columns] = np.rint(dfs[score_columns].to_numpy() / 1000)  # Banker's rounding / Round half to even\n",
    "        dfs[score_columns] = dfs[score_columns].astype('int8')\n",
    "\n",
    "        # Pandas DataFrame to Torch Tensor\n",
    "        mega_array = dfs.to_numpy()\n",
    "\n",
    "        # Rolling Columns, or: Emulating Relativeness:\n",
    "        # ---------------------\n",
    "        # To make the final data more uniform, we align the data such that it is always relative to current player POV.\n",
    "        # This entails switching the position of:\n",
    "        # - players' hands\n",
    "        # - players' melds\n",
    "        # - players' pools\n",
    "        # - players' discards\n",
    "        # - players' start score\n",
    "        # - players' end score\n",
    "        #\n",
    "        # The rotation is counter-clockwise (as this is more aligned with the actual rules of Riichi Mahjong):\n",
    "        # - `player 0` = Yourself\n",
    "        # - `player 1` = *Shimocha* - Opponent on your right\n",
    "        # - `player 2` = *Toimen* - Opponent across the board\n",
    "        # - `player 3` = *Kamicha* - Opponent on your left\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Roll Columns]\"))\n",
    "\n",
    "        roll_columns(mega_array, indices.index('player'), indices.index('p0_hand'))\n",
    "        roll_columns(mega_array, indices.index('player'), indices.index('p0_meld'))\n",
    "        roll_columns(mega_array, indices.index('player'), indices.index('p0_pool'))\n",
    "        roll_columns(mega_array, indices.index('player'), indices.index('p0_discard'))\n",
    "        roll_columns(mega_array, indices.index('player'), indices.index('p0_riichi'))\n",
    "        roll_columns(mega_array, indices.index('player'), indices.index('p0_start_score'))\n",
    "        # roll_columns(mega_array, indices.index('player'), indices.index('p0_end_score'))\n",
    "\n",
    "        # ## Transform Data to Shaped Data\n",
    "        # This is the step where we pick and select the data we want and organize it into the shape we want.\n",
    "\n",
    "        # ### Input Data X\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Explode State Columns into Matrices]\"))\n",
    "\n",
    "        pov_hand = mega_array[:, indices.index('p0_hand')]  # Due to column roll, p0 is always POV\n",
    "\n",
    "        array34_pov_hand = column_to_34_nparray(pov_hand)\n",
    "\n",
    "        array34_melds = np.concatenate(\n",
    "            [column_to_34_nparray(mega_array[:, indices.index('p0_meld') + i]) for i in range(4)],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        array34_pools = np.concatenate(\n",
    "            [column_to_34_nparray(mega_array[:, indices.index('p0_pool') + i]) for i in range(4)],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        array34_discards = np.concatenate(\n",
    "            [column_to_34_nparray(mega_array[:, indices.index('p0_discard') + i]) for i in range(4)],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        array34_doras = column_to_34_nparray(mega_array[:, indices.index('dora')])\n",
    "\n",
    "        metadata = np.column_stack((\n",
    "            mega_array[:, indices.index('round_wind')],\n",
    "            mega_array[:, indices.index('dealer')],\n",
    "            mega_array[:, indices.index('player')],\n",
    "            mega_array[:, indices.index('honba')],\n",
    "            mega_array[:, indices.index('riichibo')],\n",
    "            mega_array[:, indices.index('wall')],\n",
    "\n",
    "            mega_array[:, indices.index('p0_start_score')],\n",
    "            mega_array[:, indices.index('p1_start_score')],\n",
    "            mega_array[:, indices.index('p2_start_score')],\n",
    "            mega_array[:, indices.index('p3_start_score')],\n",
    "\n",
    "            mega_array[:, indices.index('p0_riichi')],\n",
    "            mega_array[:, indices.index('p1_riichi')],\n",
    "            mega_array[:, indices.index('p2_riichi')],\n",
    "            mega_array[:, indices.index('p3_riichi')],\n",
    "        )).astype(np.int8)\n",
    "        \n",
    "        metadata_round_num = mega_array[:, indices.index('round')].reshape(-1, 1)\n",
    "        metadata_steps = (mega_array[:, indices.index('step')] + np.iinfo(np.int8).min).reshape(-1, 1)  # As steps can easily pass +127, we offset it by -128 to fit int8.\n",
    "        n_temp_metadata = 2  # We will inject temporary data into the array. These data will NOT be used during training as they are part of perfect information set.\n",
    "        \n",
    "        padding = np.full((len(mega_array), 34 - metadata.shape[1] - n_temp_metadata), np.iinfo(np.int8).min, dtype=np.int8)  # Padding\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Finalizing Numpy Array Data]\"))\n",
    "\n",
    "        X = np.concatenate(\n",
    "            [\n",
    "                metadata,\n",
    "                padding,\n",
    "                metadata_round_num,  # Temporary Data\n",
    "                metadata_steps,      # Temporary Data\n",
    "                array34_doras,\n",
    "                array34_pov_hand,\n",
    "                array34_melds,\n",
    "                array34_pools,\n",
    "                array34_discards\n",
    "            ],\n",
    "            axis=1\n",
    "        ).astype(np.int8)\n",
    "        \n",
    "        y = mega_array[:, indices.index('tile')].astype(np.uint8) // 4  # Must be uint8 here or it will miscalculate\n",
    "\n",
    "        A = np.column_stack((X, y))\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"[Saving Array as SciPy Sparse Array to Disk]\"))\n",
    "        # save_npz(Path(OUTPUT_PATH) / f'{CURRENT_FILE_INDEX}.npz', csr_matrix(A).astype(np.int8))\n",
    "        save_npz(Path(OUTPUT_PATH) / str(year) / f'{chunk.stem}.npz', csr_matrix(A).astype(np.int8))\n",
    "\n",
    "        # CURRENT_FILE_INDEX += 1\n",
    "\n",
    "#         chunk_bar.set_description(\"{:<40}\".format(\"Done\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
