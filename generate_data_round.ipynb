{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/MasterThesis/mahjong_project/utilities/utilities.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange, tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import utilities.utilities as util\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv('config.env'))\n",
    "\n",
    "JSON_LOGS_PATH = Path(os.environ.get('JSON_DATASET'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify `fastparquet` is installed\n",
    "We will need `fastparquet` to store Pandas DataFrame with string categorial data. Note: `pyarrow` will not support this!\n",
    "If the following line crashes, install `snappy` and `fastparquet` through conda by executing: `conda install -c conda-forge python-snappy fastparquet snappy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parquet.FastParquetImpl at 0x7f9fbc5c5ca0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.io.parquet.get_engine('fastparquet')  # if this line crash, run 'conda install -c conda-forge python-snappy fastparquet snappy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INSTALLED VERSIONS\n",
      "------------------\n",
      "commit           : b5958ee1999e9aead1938c0bba2b674378807b3d\n",
      "python           : 3.8.6.final.0\n",
      "python-bits      : 64\n",
      "OS               : Linux\n",
      "OS-release       : 4.15.0-112-generic\n",
      "Version          : #113-Ubuntu SMP Thu Jul 9 23:41:39 UTC 2020\n",
      "machine          : x86_64\n",
      "processor        : x86_64\n",
      "byteorder        : little\n",
      "LC_ALL           : en_US.UTF-8\n",
      "LANG             : en_US.UTF-8\n",
      "LOCALE           : en_US.UTF-8\n",
      "\n",
      "pandas           : 1.1.5\n",
      "numpy            : 1.19.5\n",
      "pytz             : 2020.5\n",
      "dateutil         : 2.8.1\n",
      "pip              : 20.3.3\n",
      "setuptools       : 49.6.0.post20210108\n",
      "Cython           : 0.29.21\n",
      "pytest           : None\n",
      "hypothesis       : None\n",
      "sphinx           : None\n",
      "blosc            : None\n",
      "feather          : None\n",
      "xlsxwriter       : None\n",
      "lxml.etree       : 4.6.3\n",
      "html5lib         : None\n",
      "pymysql          : None\n",
      "psycopg2         : None\n",
      "jinja2           : 2.11.2\n",
      "IPython          : 7.19.0\n",
      "pandas_datareader: None\n",
      "bs4              : 4.9.3\n",
      "bottleneck       : 1.3.2\n",
      "fsspec           : 0.8.5\n",
      "fastparquet      : 0.5.0\n",
      "gcsfs            : None\n",
      "matplotlib       : 3.3.3\n",
      "numexpr          : 2.7.2\n",
      "odfpy            : None\n",
      "openpyxl         : None\n",
      "pandas_gbq       : None\n",
      "pyarrow          : None\n",
      "pytables         : None\n",
      "pyxlsb           : None\n",
      "s3fs             : None\n",
      "scipy            : 1.5.3\n",
      "sqlalchemy       : 1.3.22\n",
      "tables           : 3.6.1\n",
      "tabulate         : None\n",
      "xarray           : None\n",
      "xlrd             : 1.2.0\n",
      "xlwt             : None\n",
      "numba            : 0.52.0\n"
     ]
    }
   ],
   "source": [
    "pd.show_versions()  # Verify: 'fastparquet : 0.5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force 'fastparquet'\n",
    "pd.set_option(\"io.parquet.engine\", 'fastparquet')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Metatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change paths accordingly\n",
    "# logs_path = Path('D:') / 'logs'\n",
    "output_path = Path('meta_tables')\n",
    "output_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate MetaTable for each Year\n",
    "We will create a checkpoint for each year as a protection against running out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object get_all_logs_annually at 0x7f9ea35e94a0>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e752c2ef0fd341199e2bd20c61434144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2009:   0%|          | 0/80156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5a41af94057e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlog_json\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_json\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprevious_dealer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Retained state per round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "years = util.get_all_logs_annually(JSON_LOGS_PATH)\n",
    "rows = []\n",
    "for year, logs in years:\n",
    "    for log_json in logs:\n",
    "\n",
    "        log = json.load(log_json.open())\n",
    "\n",
    "        previous_dealer = 0  # Retained state per round\n",
    "        round_wind = 0\n",
    "        seat_wind = 0  # From player 0's POV\n",
    "\n",
    "        for round_number, actions in enumerate(log['rounds']):\n",
    "\n",
    "            init = actions.pop(0)\n",
    "            if init['tag'] != 'INIT':\n",
    "                raise Exception(f\"{log_json.name} does not have INIT!\")\n",
    "\n",
    "            # Check if dealership has been transferred\n",
    "            current_dealer = int(init['data']['oya'])\n",
    "            if previous_dealer != current_dealer:\n",
    "                previous_dealer = current_dealer\n",
    "\n",
    "                # Check if game has completed a full circle\n",
    "                if current_dealer == 0:\n",
    "                    round_wind += 1\n",
    "                    if round_wind > 3:\n",
    "                        round_wind = 0\n",
    "                # round_wind, seat_wind = next_seat_wind(round_wind, seat_wind)\n",
    "\n",
    "            # Check if there's any winners or exhaustive/abortive draw\n",
    "            winner = -1\n",
    "            if actions[-1]['tag'] == 'AGARI':\n",
    "                winner = actions[-1]['data']['winner']\n",
    "\n",
    "            # Scores\n",
    "            scores = init['data']['scores']\n",
    "            end_scores = actions[-1]['data']['scores']\n",
    "\n",
    "            # Row Creation\n",
    "            rows.append({\n",
    "                'log_id': log_json.stem,\n",
    "                'round': round_number,\n",
    "\n",
    "                'round_wind': round_wind,\n",
    "                'dealer': current_dealer,\n",
    "                'winner': winner,\n",
    "\n",
    "                # 'seat_wind': seat_wind,\n",
    "\n",
    "                'honba': init['data']['combo'],\n",
    "                'riichibo': init['data']['reach'],\n",
    "\n",
    "\n",
    "                'p0_start_score': scores[0],\n",
    "                'p1_start_score': scores[1],\n",
    "                'p2_start_score': scores[2],\n",
    "                'p3_start_score': scores[3],\n",
    "\n",
    "                'p0_end_score': end_scores[0],\n",
    "                'p1_end_score': end_scores[1],\n",
    "                'p2_end_score': end_scores[2],\n",
    "                'p3_end_score': end_scores[3],\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all MetaTables into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change Column Type to lower memory usage\n",
    "We want to lower the memory usage by our Merged MetaTable DataFrame, from about 2 GB -> 1 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "\n",
    "df['log_id'] = df['log_id'].astype('category')\n",
    "df['round'] = df['round'].astype('category')\n",
    "\n",
    "categorical_cols = ['round_wind', 'dealer', 'winner']\n",
    "df[categorical_cols] = df[categorical_cols].astype('category')\n",
    "\n",
    "cols = ['honba', 'riichibo']\n",
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], downcast='unsigned')\n",
    "\n",
    "for i in range(4):\n",
    "    df[f'p{i}_start_score'] = pd.to_numeric(df[f'p{i}_start_score'], downcast='integer')\n",
    "    df[f'p{i}_end_score'] = pd.to_numeric(df[f'p{i}_end_score'], downcast='integer')\n",
    "\n",
    "df.set_index(['log_id', 'round'], inplace=True)  # Create MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(output_path / 'log_round_meta.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(Path('log_round_meta.parquet'), engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_path / 'log_round_meta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if newly created optimized version works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated = pd.read_parquet(Path('E:') / 'mahjong' / 'pandas' / 'log_round_meta.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated.loc['2019123123gm-00e1-0000-f7f33877', 3]  # Accessing MultiIndexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
